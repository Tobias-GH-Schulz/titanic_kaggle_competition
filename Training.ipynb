{"cells":[{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T14:10:26.044885Z","start_time":"2021-01-30T14:10:26.033543Z"},"cell_id":"00000-f3de8d9a-9007-4fe1-9480-8e83b4b1ae26","deepnote_to_be_reexecuted":false,"execution_millis":13,"source_hash":"b60bd3a1","tags":[],"execution_start":1612023666168,"deepnote_cell_type":"code"},"source":"import pandas as pd\nimport numpy as np\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\n\n\n#from xgboost import XGBClassifier\nfrom sklearn import model_selection\nfrom sklearn.utils import class_weight\n\nimport numpy as np\nimport pandas as pd\n\n\n\ndata = pd.read_csv('Train_clean.csv')\ndata  = data.drop(\"not_alone\", axis=1)\n#test  = test.drop(\"not_alone\", axis=1)\n\ndata  = data.drop(\"Parch\", axis=1)\n#test  = test.drop(\"Parch\", axis=1)","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T14:10:28.550967Z","start_time":"2021-01-30T14:10:28.545199Z"},"cell_id":"00003-607f4d20-67e1-44f0-81d6-a37a24715feb","deepnote_to_be_reexecuted":false,"execution_millis":2,"source_hash":"9a7fe698","tags":[],"execution_start":1612023670468,"deepnote_cell_type":"code"},"source":"X = data.drop(columns=['Survived', \"Unnamed: 0\"], axis=1)\ny = data.Survived\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=0)\n","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T14:10:31.577177Z","start_time":"2021-01-30T14:10:31.568271Z"},"cell_id":"00004-68e192ee-1a06-408d-a803-83143f5eb94e","deepnote_to_be_reexecuted":false,"execution_millis":5,"source_hash":"580fdd9e","tags":[],"execution_start":1612023673140,"deepnote_cell_type":"code"},"source":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train_norm = scaler.transform(X_train)\nX_test_norm = scaler.transform(X_test)","execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Classifier","metadata":{"tags":[],"cell_id":"00003-001f2270-f8e2-467e-9db9-6acf255ac729","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T14:10:34.471039Z","start_time":"2021-01-30T14:10:34.265419Z"},"cell_id":"00003-ef1f89b6-ece9-42e9-93f7-b3e651cbf628","deepnote_to_be_reexecuted":false,"source_hash":"2662f3e8","execution_millis":543,"execution_start":1612023679181,"deepnote_cell_type":"code"},"source":"random_forest = RandomForestClassifier(criterion = \"gini\", \n                                       min_samples_leaf = 1, \n                                       min_samples_split = 10,   \n                                       n_estimators=100, \n                                       max_features='auto', \n                                       oob_score=True, \n                                       random_state=1, \n                                       n_jobs=-1)\n\nrandom_forest.fit(X_train_norm, y_train)\nY_prediction = random_forest.predict(X_test_norm)\n\nrandom_forest.score(X_train_norm, y_train)\n\nacc_random_forest = round(random_forest.score(X_train_norm, y_train) * 100, 2)\nprint(round(acc_random_forest,2,), \"%\")","execution_count":15,"outputs":[{"name":"stdout","text":"88.48 %\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T14:10:39.893208Z","start_time":"2021-01-30T14:10:39.873663Z"},"scrolled":true,"cell_id":"00004-a2e932d2-8d95-4472-86ba-000556c5c19e","deepnote_to_be_reexecuted":false,"source_hash":"f805a6c7","execution_millis":34,"execution_start":1612019105292,"deepnote_cell_type":"code"},"source":"importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances.head(15)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":9,"column_count":1,"columns":[{"name":"importance","dtype":"float64","stats":{"unique_count":9,"nan_count":0,"min":0.033,"max":0.268,"histogram":[{"bin_start":0.033,"bin_end":0.0565,"count":2},{"bin_start":0.0565,"bin_end":0.08,"count":3},{"bin_start":0.08,"bin_end":0.10350000000000001,"count":0},{"bin_start":0.10350000000000001,"bin_end":0.127,"count":1},{"bin_start":0.127,"bin_end":0.1505,"count":1},{"bin_start":0.1505,"bin_end":0.17400000000000002,"count":0},{"bin_start":0.17400000000000002,"bin_end":0.1975,"count":0},{"bin_start":0.1975,"bin_end":0.221,"count":1},{"bin_start":0.221,"bin_end":0.2445,"count":0},{"bin_start":0.2445,"bin_end":0.268,"count":1}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows_top":[{"importance":0.268,"_deepnote_index_column":"Fare"},{"importance":0.203,"_deepnote_index_column":"Title"},{"importance":0.148,"_deepnote_index_column":"Sex"},{"importance":0.11,"_deepnote_index_column":"Age"},{"importance":0.067,"_deepnote_index_column":"relatives"},{"importance":0.063,"_deepnote_index_column":"Pclass"},{"importance":0.059,"_deepnote_index_column":"Deck"},{"importance":0.05,"_deepnote_index_column":"SibSp"},{"importance":0.033,"_deepnote_index_column":"Embarked"}],"rows_bottom":null},"text/plain":"           importance\nfeature              \nFare            0.268\nTitle           0.203\nSex             0.148\nAge             0.110\nrelatives       0.067\nPclass          0.063\nDeck            0.059\nSibSp           0.050\nEmbarked        0.033","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n    </tr>\n    <tr>\n      <th>feature</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Fare</th>\n      <td>0.268</td>\n    </tr>\n    <tr>\n      <th>Title</th>\n      <td>0.203</td>\n    </tr>\n    <tr>\n      <th>Sex</th>\n      <td>0.148</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>0.110</td>\n    </tr>\n    <tr>\n      <th>relatives</th>\n      <td>0.067</td>\n    </tr>\n    <tr>\n      <th>Pclass</th>\n      <td>0.063</td>\n    </tr>\n    <tr>\n      <th>Deck</th>\n      <td>0.059</td>\n    </tr>\n    <tr>\n      <th>SibSp</th>\n      <td>0.050</td>\n    </tr>\n    <tr>\n      <th>Embarked</th>\n      <td>0.033</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T14:10:43.785937Z","start_time":"2021-01-30T14:10:43.641832Z"},"scrolled":false,"cell_id":"00005-e2e10778-e4da-4abd-a753-79237fb930bf","deepnote_to_be_reexecuted":false,"source_hash":"3c2b6713","execution_start":1612019107837,"execution_millis":1079,"deepnote_cell_type":"code"},"source":"importances.plot.bar();","execution_count":null,"outputs":[{"name":"stderr","text":"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/backend/resource_tracker.py:120: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some folders/sempahores might leak.\n  warnings.warn('resource_tracker: process died unexpectedly, '\n","output_type":"stream"},{"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"start_time":"2021-01-30T14:14:56.086Z"},"cell_id":"00006-bd460b3a-46fe-43a7-b4c4-ce59c0f3bf03","deepnote_to_be_reexecuted":false,"source_hash":null,"execution_start":1612016768333,"execution_millis":91,"output_cleared":true,"deepnote_cell_type":"code"},"source":"param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10, 25, 50, 70], \"min_samples_split\" : [2, 4, 10, 12, 16, 18, 25, 35], \"n_estimators\": [100, 400, 700, 1000, 1500]}\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nrf = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\nclf = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1)\nclf.fit(X_train_norm, y_train)\nclf.bestparams","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00007-02b2241f-dd5c-422c-a1ad-fc9b4964590a","deepnote_to_be_reexecuted":false,"source_hash":"a9bbc29a","execution_millis":65,"execution_start":1612023726581,"deepnote_cell_type":"code"},"source":"from sklearn.metrics import roc_auc_score\ny_scores = random_forest.predict_proba(X_train_norm)\ny_scores = y_scores[:,1]\n\nr_a_score = roc_auc_score(y_train, y_scores)\nprint(\"ROC-AUC-Score:\", r_a_score)","execution_count":16,"outputs":[{"name":"stdout","text":"ROC-AUC-Score: 0.940457416539421\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00008-100f6b72-6767-4c63-b937-93fad04f46a9","deepnote_to_be_reexecuted":false,"source_hash":"d7e6422f","execution_millis":174,"execution_start":1612023732147,"deepnote_cell_type":"code"},"source":"from sklearn.metrics import precision_recall_curve\n\nprecision, recall, threshold = precision_recall_curve(y_train, y_scores)\ndef plot_precision_and_recall(precision, recall, threshold):\n    plt.plot(threshold, precision[:-1], \"r-\", label=\"precision\", linewidth=5)\n    plt.plot(threshold, recall[:-1], \"b\", label=\"recall\", linewidth=5)\n    plt.xlabel(\"threshold\", fontsize=19)\n    plt.legend(loc=\"upper right\", fontsize=19)\n    plt.ylim([0, 1])\n\nplt.figure(figsize=(14, 7))\nplot_precision_and_recall(precision, recall, threshold)\nplt.show()","execution_count":17,"outputs":[{"data":{"text/plain":"<Figure size 1008x504 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"},"output_type":"display_data"}]},{"cell_type":"markdown","source":"### SVC","metadata":{"tags":[],"cell_id":"00010-8761cf6d-2dbd-48ec-93fc-efcdebf2b0df","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# defining parameter range \nparam_grid = {'C': [0.1, 1, 10, 1000],  \n              'gamma': ['scale', 1, 0.1, 0.0001], 'kernel': ['poly', 'rbf']}  \n  \ngrid = GridSearchCV(SVC(), param_grid, verbose=1) \n  ","metadata":{"tags":[],"cell_id":"00010-75303f64-cd74-4e60-aca9-d92fdbb27eca","deepnote_to_be_reexecuted":false,"source_hash":"b3d7ed8a","execution_millis":9,"execution_start":1612025367423,"deepnote_cell_type":"code"},"outputs":[],"execution_count":24},{"cell_type":"code","source":"grid.fit(X_train_norm, y_train) \n\n# print best parameter after tuning \nprint(grid.best_params_) \n  \n# print how our model looks after hyper-parameter tuning \nprint(grid.best_estimator_) ","metadata":{"tags":[],"cell_id":"00011-f70365b0-8745-45c9-9c0d-9367f4f9232f","deepnote_to_be_reexecuted":false,"source_hash":"4120ee57","execution_millis":1186868,"execution_start":1612025369666,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 32 candidates, totalling 160 fits\n{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\nSVC(C=1)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"svc_pred = grid.predict(X_test_norm)","metadata":{"tags":[],"cell_id":"00013-4f2e031a-26a4-432b-b352-12472c0b3788","deepnote_to_be_reexecuted":false,"source_hash":"9dedd157","execution_start":1612026812244,"execution_millis":13,"deepnote_cell_type":"code"},"outputs":[],"execution_count":26},{"cell_type":"code","source":"accuracy_score(y_test, svc_pred)","metadata":{"tags":[],"cell_id":"00014-b10b9f3d-be3e-4152-99ea-e642c688be42","deepnote_to_be_reexecuted":false,"source_hash":"60279ccd","execution_start":1612041621597,"execution_millis":1,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"0.8268156424581006"},"metadata":{}}],"execution_count":32},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T13:59:17.868367Z","start_time":"2021-01-30T13:59:17.856058Z"},"cell_id":"00002-b30a25cc-a956-4747-9558-6dff7cf902a1","deepnote_to_be_reexecuted":false,"execution_millis":3,"execution_start":1611989958749,"source_hash":"a5eb888b","tags":[],"deepnote_cell_type":"code"},"source":"class EstimatorSelectionHelper:\n\n    def __init__(self, models, params):\n        if not set(models.keys()).issubset(set(params.keys())):\n            missing_params = list(set(models.keys()) - set(params.keys()))\n            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n        self.models = models\n        self.params = params\n        self.keys = models.keys()\n        self.grid_searches = {}\n\n    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n        for key in self.keys:\n            print(\"Running GridSearchCV for %s.\" % key)\n            model = self.models[key]\n            params = self.params[key]\n            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n                              verbose=verbose, scoring=scoring, refit=refit,\n                              return_train_score=True)\n            gs.fit(X,y)\n            self.grid_searches[key] = gs    \n\n    def score_summary(self, sort_by='mean_score'):\n        def row(key, scores, params):\n            d = {\n                 'estimator': key,\n                 'min_score': min(scores),\n                 'max_score': max(scores),\n                 'mean_score': np.mean(scores),\n                 'std_score': np.std(scores),\n            }\n            return pd.Series({**params,**d})\n\n        rows = []\n        for k in self.grid_searches:\n            print(k)\n            params = self.grid_searches[k].cv_results_['params']\n            scores = []\n            for i in range(self.grid_searches[k].cv):\n                key = \"split{}_test_score\".format(i)\n                r = self.grid_searches[k].cv_results_[key]        \n                scores.append(r.reshape(len(params),1))\n\n            all_scores = np.hstack(scores)\n            for p, s in zip(params,all_scores):\n                rows.append((row(k, s, p)))\n\n        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n\n        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n        columns = columns + [c for c in df.columns if c not in columns]\n\n        return df[columns]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T14:00:24.356908Z","start_time":"2021-01-30T14:00:24.353036Z"},"cell_id":"00003-a394d79d-9ee0-4694-a65f-febac2dc5504","deepnote_to_be_reexecuted":false,"execution_millis":0,"execution_start":1611995101277,"source_hash":"ccf0ff73","tags":[],"deepnote_cell_type":"code"},"source":"models1 = {\n    'ExtraTreesClassifier': ExtraTreesClassifier(),\n    'RandomForestClassifier': RandomForestClassifier(),\n    'AdaBoostClassifier': AdaBoostClassifier(),\n    'GradientBoostingClassifier': GradientBoostingClassifier(),\n}\n\nparams1 = {\n    'ExtraTreesClassifier': {'n_estimators': [16, 32] },\n    'RandomForestClassifier': {'n_estimators': [16, 32] },\n    'AdaBoostClassifier':  {'n_estimators': [16, 32] },\n    'GradientBoostingClassifier': {'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] }\n}","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00004-504395c2-f53c-4766-87a0-7a4de61224b1","tags":[],"deepnote_cell_type":"code"},"source":"models2 = {\n    'ExtraTreesClassifier': ExtraTreesClassifier(),\n    'RandomForestClassifier': RandomForestClassifier(),\n    'AdaBoostClassifier': AdaBoostClassifier(),\n    'GradientBoostingClassifier': GradientBoostingClassifier(),\n    'SVC': SVC(),\n}\n\nparams2 = {\n    'ExtraTreesClassifier': {'n_estimators': [16, 32] },\n    'RandomForestClassifier': {'n_estimators': [16, 32] },\n    'AdaBoostClassifier':  {'n_estimators': [16, 32] },\n    'GradientBoostingClassifier': {'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n    'SVC': [\n        {'kernel': ['linear'], 'C': [1, 10, 100]},\n        {'kernel': ['rbf', 'poly', 'sigmoid', 'linear'], 'C':[0.1, 1, 10, 100], 'gamma': [1,0.1,0.01,0.001]},\n    ]\n}","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T11:27:00.841630Z","start_time":"2021-01-30T11:27:00.636220Z"},"cell_id":"00008-b5a603c8-2bd5-43b9-9ad8-d31dcc707978","deepnote_to_be_reexecuted":false,"execution_millis":255,"execution_start":1612007250508,"output_cleared":true,"source_hash":null,"tags":[],"deepnote_cell_type":"code"},"source":"pred = clf.predict(X_test_norm)\n\nclf.score(X_test_norm, y_test)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T13:50:38.809632Z","start_time":"2021-01-30T13:50:38.805836Z"},"cell_id":"00009-205f02fa-45c8-4e2d-b29c-dcad02dad41f","tags":[],"deepnote_cell_type":"code"},"source":"10.0 ** -np.arange(1, 5)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T14:00:34.960826Z","start_time":"2021-01-30T14:00:34.944269Z"},"cell_id":"00001-6006f514-39f9-4243-9f66-02c6ac82ff91","deepnote_to_be_reexecuted":false,"execution_millis":97,"execution_start":1611990033981,"source_hash":"1cb720cd","tags":[],"deepnote_cell_type":"code"},"source":"helper1 = EstimatorSelectionHelper(models1, params1)\nhelper1.fit(X_train_norm, y_train, scoring='f1', n_jobs=2)","execution_count":null,"outputs":[{"name":"stdout","text":"Running GridSearchCV for ExtraTreesClassifier.\nFitting 3 folds for each of 2 candidates, totalling 6 fits\n/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/backend/resource_tracker.py:120: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some folders/sempahores might leak.\n  warnings.warn('resource_tracker: process died unexpectedly, '\nexception calling callback for <Future at 0x7fc790ab3590 state=finished raised TerminatedWorkerError>\nTraceback (most recent call last):\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n    callback(self)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 359, in __call__\n    self.parallel.dispatch_next()\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 792, in dispatch_next\n    if not self.dispatch_one_batch(self._original_iterator):\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 777, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n    future = self._workers.submit(SafeFunction(func))\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\", line 178, in submit\n    fn, *args, **kwargs)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 1102, in submit\n    raise self._flags.broken\njoblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1)}\n/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/backend/resource_tracker.py:120: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some folders/sempahores might leak.\n  warnings.warn('resource_tracker: process died unexpectedly, '\n","output_type":"stream"},{"output_type":"error","ename":"TerminatedWorkerError","evalue":"A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1)}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-55c3ef2e8eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhelper1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEstimatorSelectionHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhelper1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-5b3de598f71b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     18\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               return_train_score=True)\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_searches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \"\"\"\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0;32m--> 178\u001b[0;31m                 fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m                 raise ShutdownExecutorError(\n","\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1)}"]}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T13:59:42.472026Z","start_time":"2021-01-30T13:59:42.439506Z"},"cell_id":"00002-212c8998-2040-4b46-9f57-35e36a76bd59","deepnote_to_be_reexecuted":true,"source_hash":"b623e53d","tags":[],"deepnote_cell_type":"code"},"source":"display(helper1.score_summary(sort_by='max_score').head(20))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T07:17:58.523966Z","start_time":"2021-01-30T07:17:58.521477Z"},"cell_id":"00008-05e6b383-ba5a-4286-b054-61003bb52ab2","deepnote_to_be_reexecuted":true,"source_hash":"440908b4","tags":[],"deepnote_cell_type":"code"},"source":"'LogReg': LogisticRegression()\n'LinReg': LinearRegression()\n'KNeighborsClassifier': KNeighborsClassifier()","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MLP","metadata":{"tags":[],"cell_id":"00023-ac3ffb39-2635-4fbe-8355-3e34ea40f67e","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00011-784f885b-d87e-4b0e-9e29-810e9d76366f","deepnote_cell_type":"code"},"source":"clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\nclf.fit(X_train_norm, y_train)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T13:57:32.806758Z","start_time":"2021-01-30T13:57:29.637407Z"},"cell_id":"00012-1166e287-38e9-455d-bdab-db12c18fe7b4","deepnote_to_be_reexecuted":false,"execution_millis":337,"execution_start":1612014358491,"source_hash":"741c1b66","tags":[],"deepnote_cell_type":"code"},"source":"mlp_gs = MLPClassifier(max_iter=50)\nparameter_space = {\n    'hidden_layer_sizes': [(10,30,10),(20,)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd'],\n    'alpha': list(10.0 ** -np.arange(1, 7)), 'random_state': [0],\n    'momentum': [0.99, 0.5, 0.1, 0.01, 0.001], 'early_stopping': [True]}\nfrom sklearn.model_selection import GridSearchCV\nmlp_clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=5)\nmlp_clf.fit(X_train_norm, y_train)","execution_count":null,"outputs":[{"name":"stderr","text":"exception calling callback for <Future at 0x7f219036ce90 state=finished raised TerminatedWorkerError>\nTraceback (most recent call last):\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n    callback(self)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 359, in __call__\n    self.parallel.dispatch_next()\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 792, in dispatch_next\n    if not self.dispatch_one_batch(self._original_iterator):\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 777, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n    future = self._workers.submit(SafeFunction(func))\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\", line 178, in submit\n    fn, *args, **kwargs)\n  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 1102, in submit\n    raise self._flags.broken\njoblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1)}\n/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/backend/resource_tracker.py:120: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some folders/sempahores might leak.\n  warnings.warn('resource_tracker: process died unexpectedly, '\n","output_type":"stream"},{"output_type":"error","ename":"TerminatedWorkerError","evalue":"A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1)}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-b2417044d4f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_gs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \"\"\"\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0;32m--> 178\u001b[0;31m                 fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m                 raise ShutdownExecutorError(\n","\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1)}"]}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T13:57:39.713987Z","start_time":"2021-01-30T13:57:39.710025Z"},"cell_id":"00019-73ba5083-fc14-44c1-9e32-d77d9fd688ed","deepnote_cell_type":"code"},"source":"mlp_clf.best_params_","execution_count":null,"outputs":[{"data":{"text/plain":"{'activation': 'tanh',\n 'alpha': 0.1,\n 'early_stopping': True,\n 'hidden_layer_sizes': (10, 30, 10),\n 'momentum': 0.99,\n 'random_state': 0,\n 'solver': 'sgd'}"},"execution_count":13,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T13:57:45.811585Z","start_time":"2021-01-30T13:57:45.806129Z"},"cell_id":"00020-9fd49fb0-54c1-41b3-bd2c-594e9f57b168","deepnote_cell_type":"code"},"source":"pred = mlp_clf.predict(X_test_norm)\n\nmlp_clf.score(X_test_norm, y_test)","execution_count":null,"outputs":[{"data":{"text/plain":"0.7932960893854749"},"execution_count":14,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-01-30T11:19:18.830143Z","start_time":"2021-01-30T11:16:35.550352Z"},"cell_id":"00012-bd537f71-6d18-4ac4-92da-cfcbfecf25b8","deepnote_to_be_reexecuted":false,"execution_millis":34990,"execution_start":1612014078635,"scrolled":false,"source_hash":"b1013a22","deepnote_cell_type":"code"},"source":"tuned_parameters = [{'alpha': list(10.0 ** -np.arange(1, 7)), 'activation': ('identity', 'logistic', 'tanh', 'relu'),\n                     'random_state': [0], 'verbose' : [3]}]\n\nscores = ['precision', 'recall']\n\n\nfor score in scores:\n    print(\"# Tuning hyper-parameters for %s\" % score)\n    print()\n\n    clf = GridSearchCV(\n        MLPClassifier(), tuned_parameters, scoring='%s_macro' % score\n    )\n    clf.fit(X_train_norm, y_train)\n\n    print(\"Best parameters set found on development set:\")\n    print()\n    print(clf.best_params_)\n    print()\n    print(\"Grid scores on development set:\")\n    print()\n    means = clf.cv_results_['mean_test_score']\n    stds = clf.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n        print(\"%0.3f (+/-%0.03f) for %r\"\n              % (mean, std * 2, params))\n    print()\n\n    print(\"Detailed classification report:\")\n    print()\n    print(\"The model is trained on the full development set.\")\n    print(\"The scores are computed on the full evaluation set.\")\n    print()\n    y_true, y_pred = y_test, clf.predict(X_test_norm)\n    print(classification_report(y_true, y_pred))\n    print()\n","execution_count":null,"outputs":[{"name":"stdout","text":"Iteration 27, loss = 0.41420798\nIteration 28, loss = 0.41352678\nIteration 29, loss = 0.41290442\nIteration 30, loss = 0.41236020\nIteration 31, loss = 0.41191421\nIteration 32, loss = 0.41169502\nIteration 33, loss = 0.41133468\nIteration 34, loss = 0.41099500\nIteration 35, loss = 0.41078443\nIteration 36, loss = 0.41059346\nIteration 37, loss = 0.41034743\nIteration 38, loss = 0.41016852\nIteration 39, loss = 0.40999217\nIteration 40, loss = 0.40987374\nIteration 41, loss = 0.40972533\nIteration 42, loss = 0.40963890\nIteration 43, loss = 0.40953258\nIteration 44, loss = 0.40936160\nIteration 45, loss = 0.40920815\nIteration 46, loss = 0.40912359\nIteration 47, loss = 0.40891048\nIteration 48, loss = 0.40877274\nIteration 49, loss = 0.40863469\nIteration 50, loss = 0.40850314\nIteration 51, loss = 0.40844405\nIteration 52, loss = 0.40831000\nIteration 53, loss = 0.40809418\nIteration 54, loss = 0.40805703\nIteration 55, loss = 0.40789685\nIteration 56, loss = 0.40777843\nIteration 57, loss = 0.40773617\nIteration 58, loss = 0.40765441\nIteration 59, loss = 0.40734714\nIteration 60, loss = 0.40722810\nIteration 61, loss = 0.40731651\nIteration 62, loss = 0.40735609\nIteration 63, loss = 0.40705611\nIteration 64, loss = 0.40686461\nIteration 65, loss = 0.40658625\nIteration 66, loss = 0.40655840\nIteration 67, loss = 0.40634327\nIteration 68, loss = 0.40639197\nIteration 69, loss = 0.40611444\nIteration 70, loss = 0.40605642\nIteration 71, loss = 0.40588233\nIteration 72, loss = 0.40579491\nIteration 73, loss = 0.40562268\nIteration 74, loss = 0.40551729\nIteration 75, loss = 0.40540174\nIteration 76, loss = 0.40533982\nIteration 77, loss = 0.40512861\nIteration 78, loss = 0.40510965\nIteration 79, loss = 0.40484282\nIteration 80, loss = 0.40478634\nIteration 81, loss = 0.40468553\nIteration 82, loss = 0.40450501\nIteration 83, loss = 0.40452853\nIteration 84, loss = 0.40431373\nIteration 85, loss = 0.40412978\nIteration 86, loss = 0.40417521\nIteration 87, loss = 0.40388893\nIteration 88, loss = 0.40390006\nIteration 89, loss = 0.40361192\nIteration 90, loss = 0.40353255\nIteration 91, loss = 0.40348599\nIteration 92, loss = 0.40331294\nIteration 93, loss = 0.40311831\nIteration 94, loss = 0.40306952\nIteration 95, loss = 0.40281864\nIteration 96, loss = 0.40302265\nIteration 97, loss = 0.40259151\nIteration 98, loss = 0.40250342\nIteration 99, loss = 0.40233853\nIteration 100, loss = 0.40235451\nIteration 101, loss = 0.40209145\nIteration 102, loss = 0.40199168\nIteration 103, loss = 0.40177305\nIteration 104, loss = 0.40174353\nIteration 105, loss = 0.40152465\nIteration 106, loss = 0.40142222\nIteration 107, loss = 0.40131221\nIteration 108, loss = 0.40133138\nIteration 109, loss = 0.40101792\nIteration 110, loss = 0.40097575\nIteration 111, loss = 0.40077692\nIteration 112, loss = 0.40055444\nIteration 113, loss = 0.40053510\nIteration 114, loss = 0.40027996\nIteration 115, loss = 0.40020192\nIteration 116, loss = 0.40007923\nIteration 117, loss = 0.39986789\nIteration 118, loss = 0.39981067\nIteration 119, loss = 0.39965036\nIteration 120, loss = 0.39948051\nIteration 121, loss = 0.39946303\nIteration 122, loss = 0.39919636\nIteration 123, loss = 0.39916664\nIteration 124, loss = 0.39912801\nIteration 125, loss = 0.39892007\nIteration 126, loss = 0.39866191\nIteration 127, loss = 0.39851836\nIteration 128, loss = 0.39836920\nIteration 129, loss = 0.39821300\nIteration 130, loss = 0.39806474\nIteration 131, loss = 0.39807198\nIteration 132, loss = 0.39776130\nIteration 133, loss = 0.39765272\nIteration 134, loss = 0.39751504\nIteration 135, loss = 0.39731429\nIteration 136, loss = 0.39715037\nIteration 137, loss = 0.39714971\nIteration 138, loss = 0.39686192\nIteration 139, loss = 0.39690699\nIteration 140, loss = 0.39674777\nIteration 141, loss = 0.39648565\nIteration 142, loss = 0.39629397\nIteration 143, loss = 0.39620442\nIteration 144, loss = 0.39599110\nIteration 145, loss = 0.39612421\nIteration 146, loss = 0.39583763\nIteration 147, loss = 0.39556858\nIteration 148, loss = 0.39556715\nIteration 149, loss = 0.39532407\nIteration 150, loss = 0.39510916\nIteration 151, loss = 0.39509200\nIteration 152, loss = 0.39480222\nIteration 153, loss = 0.39467426\nIteration 154, loss = 0.39461496\nIteration 155, loss = 0.39479387\nIteration 156, loss = 0.39413297\nIteration 157, loss = 0.39399333\nIteration 158, loss = 0.39390673\nIteration 159, loss = 0.39370574\nIteration 160, loss = 0.39358935\nIteration 161, loss = 0.39334892\nIteration 162, loss = 0.39335816\nIteration 163, loss = 0.39310039\nIteration 164, loss = 0.39291349\nIteration 165, loss = 0.39288109\nIteration 166, loss = 0.39266014\nIteration 167, loss = 0.39251133\nIteration 168, loss = 0.39227840\nIteration 169, loss = 0.39224802\nIteration 170, loss = 0.39193075\nIteration 171, loss = 0.39172977\nIteration 172, loss = 0.39170812\nIteration 173, loss = 0.39159032\nIteration 174, loss = 0.39129402\nIteration 175, loss = 0.39105600\nIteration 176, loss = 0.39135475\nIteration 177, loss = 0.39093484\nIteration 178, loss = 0.39071448\nIteration 179, loss = 0.39058892\nIteration 180, loss = 0.39030546\nIteration 181, loss = 0.39031989\nIteration 182, loss = 0.39000024\nIteration 183, loss = 0.38995182\nIteration 184, loss = 0.38971307\nIteration 185, loss = 0.38963368\nIteration 186, loss = 0.38936247\nIteration 187, loss = 0.38935814\nIteration 188, loss = 0.38900175\nIteration 189, loss = 0.38882879\nIteration 190, loss = 0.38880803\nIteration 191, loss = 0.38841697\nIteration 192, loss = 0.38839634\nIteration 193, loss = 0.38818780\nIteration 194, loss = 0.38815772\nIteration 195, loss = 0.38802441\nIteration 196, loss = 0.38770687\nIteration 197, loss = 0.38738552\nIteration 198, loss = 0.38736928\nIteration 199, loss = 0.38716175\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\nIteration 200, loss = 0.38702878\nIteration 1, loss = 0.75832456\nIteration 2, loss = 0.71171039\nIteration 3, loss = 0.66908978\nIteration 4, loss = 0.63545083\nIteration 5, loss = 0.60680628\nIteration 6, loss = 0.58225380\nIteration 7, loss = 0.56040464\nIteration 8, loss = 0.54365459\nIteration 9, loss = 0.52775228\nIteration 10, loss = 0.51479965\nIteration 11, loss = 0.50303278\nIteration 12, loss = 0.49322982\nIteration 13, loss = 0.48382353\nIteration 14, loss = 0.47646565\nIteration 15, loss = 0.46965282\nIteration 16, loss = 0.46390666\nIteration 17, loss = 0.45887594\nIteration 18, loss = 0.45518417\nIteration 19, loss = 0.45147907\nIteration 20, loss = 0.44831786\nIteration 21, loss = 0.44584141\nIteration 22, loss = 0.44361769\nIteration 23, loss = 0.44229591\nIteration 24, loss = 0.44069308\nIteration 25, loss = 0.43972276\nIteration 26, loss = 0.43856770\nIteration 27, loss = 0.43787131\nIteration 28, loss = 0.43722117\nIteration 29, loss = 0.43645116\nIteration 30, loss = 0.43609639\nIteration 31, loss = 0.43551459\nIteration 32, loss = 0.43535283\nIteration 33, loss = 0.43495016\nIteration 34, loss = 0.43457925\nIteration 35, loss = 0.43431085\nIteration 36, loss = 0.43416272\nIteration 37, loss = 0.43385617\nIteration 38, loss = 0.43367446\nIteration 39, loss = 0.43348782\nIteration 40, loss = 0.43342159\nIteration 41, loss = 0.43312504\nIteration 42, loss = 0.43304791\nIteration 43, loss = 0.43291141\nIteration 44, loss = 0.43278707\nIteration 45, loss = 0.43255913\nIteration 46, loss = 0.43244030\nIteration 47, loss = 0.43227622\nIteration 48, loss = 0.43218995\nIteration 49, loss = 0.43208251\nIteration 50, loss = 0.43196295\nIteration 51, loss = 0.43182412\nIteration 52, loss = 0.43164683\nIteration 53, loss = 0.43154447\nIteration 54, loss = 0.43144968\nIteration 55, loss = 0.43128637\nIteration 56, loss = 0.43119653\nIteration 57, loss = 0.43105918\nIteration 58, loss = 0.43095178\nIteration 59, loss = 0.43080071\nIteration 60, loss = 0.43073039\nIteration 61, loss = 0.43068113\nIteration 62, loss = 0.43050218\nIteration 63, loss = 0.43032608\nIteration 64, loss = 0.43028896\nIteration 65, loss = 0.43007265\nIteration 66, loss = 0.43004319\nIteration 67, loss = 0.42980009\nIteration 68, loss = 0.42986655\nIteration 69, loss = 0.42971458\nIteration 70, loss = 0.42953243\nIteration 71, loss = 0.42937826\nIteration 72, loss = 0.42919914\nIteration 73, loss = 0.42921312\nIteration 74, loss = 0.42908183\nIteration 75, loss = 0.42889643\nIteration 76, loss = 0.42881326\nIteration 77, loss = 0.42864137\nIteration 78, loss = 0.42853673\nIteration 79, loss = 0.42835868\nIteration 80, loss = 0.42825301\nIteration 81, loss = 0.42835717\nIteration 82, loss = 0.42801414\nIteration 83, loss = 0.42818806\nIteration 84, loss = 0.42783339\nIteration 85, loss = 0.42761297\nIteration 86, loss = 0.42751908\nIteration 87, loss = 0.42744036\nIteration 88, loss = 0.42735742\nIteration 89, loss = 0.42716826\nIteration 90, loss = 0.42706531\nIteration 91, loss = 0.42704405\nIteration 92, loss = 0.42680241\nIteration 93, loss = 0.42663561\nIteration 94, loss = 0.42687294\nIteration 95, loss = 0.42650003\nIteration 96, loss = 0.42638021\nIteration 97, loss = 0.42625089\nIteration 98, loss = 0.42628804\nIteration 99, loss = 0.42598435\nIteration 100, loss = 0.42584507\nIteration 101, loss = 0.42579035\nIteration 102, loss = 0.42563571\nIteration 103, loss = 0.42553876\nIteration 104, loss = 0.42538356\nIteration 105, loss = 0.42541670\nIteration 106, loss = 0.42510380\nIteration 107, loss = 0.42494520\nIteration 108, loss = 0.42486613\nIteration 109, loss = 0.42474291\nIteration 110, loss = 0.42463552\nIteration 111, loss = 0.42454258\nIteration 112, loss = 0.42428126\nIteration 113, loss = 0.42429561\nIteration 114, loss = 0.42405354\nIteration 115, loss = 0.42397731\nIteration 116, loss = 0.42400499\nIteration 117, loss = 0.42372603\nIteration 118, loss = 0.42362567\nIteration 119, loss = 0.42352972\nIteration 120, loss = 0.42329969\nIteration 121, loss = 0.42332145\nIteration 122, loss = 0.42311123\nIteration 123, loss = 0.42295521\nIteration 124, loss = 0.42293622\nIteration 125, loss = 0.42268475\nIteration 126, loss = 0.42260736\nIteration 127, loss = 0.42239074\nIteration 128, loss = 0.42218532\nIteration 129, loss = 0.42227088\nIteration 130, loss = 0.42204903\nIteration 131, loss = 0.42192339\nIteration 132, loss = 0.42171876\nIteration 133, loss = 0.42168535\nIteration 134, loss = 0.42148389\nIteration 135, loss = 0.42137394\nIteration 136, loss = 0.42116455\nIteration 137, loss = 0.42112799\nIteration 138, loss = 0.42088920\nIteration 139, loss = 0.42118739\nIteration 140, loss = 0.42071229\nIteration 141, loss = 0.42074136\nIteration 142, loss = 0.42037979\nIteration 143, loss = 0.42024110\nIteration 144, loss = 0.42013896\nIteration 145, loss = 0.42003779\nIteration 146, loss = 0.41997541\nIteration 147, loss = 0.41976172\nIteration 148, loss = 0.41976130\nIteration 149, loss = 0.41945519\nIteration 150, loss = 0.41921402\nIteration 151, loss = 0.41923311\nIteration 152, loss = 0.41902584\nIteration 153, loss = 0.41879022\nIteration 154, loss = 0.41890437\nIteration 155, loss = 0.41906926\nIteration 156, loss = 0.41849188\nIteration 157, loss = 0.41827165\nIteration 158, loss = 0.41823477\nIteration 159, loss = 0.41828071\nIteration 160, loss = 0.41783146\nIteration 161, loss = 0.41772492\nIteration 162, loss = 0.41772731\nIteration 163, loss = 0.41751204\nIteration 164, loss = 0.41724267\nIteration 165, loss = 0.41717906\nIteration 166, loss = 0.41706908\nIteration 167, loss = 0.41696108\nIteration 168, loss = 0.41668694\nIteration 169, loss = 0.41655511\nIteration 170, loss = 0.41645120\nIteration 171, loss = 0.41639993\nIteration 172, loss = 0.41612656\nIteration 173, loss = 0.41610258\nIteration 174, loss = 0.41588099\nIteration 175, loss = 0.41579163\nIteration 176, loss = 0.41573125\nIteration 177, loss = 0.41543041\nIteration 178, loss = 0.41536297\nIteration 179, loss = 0.41509700\nIteration 180, loss = 0.41501808\nIteration 181, loss = 0.41491652\nIteration 182, loss = 0.41455405\nIteration 183, loss = 0.41444035\nIteration 184, loss = 0.41433950\nIteration 185, loss = 0.41421429\nIteration 186, loss = 0.41399110\nIteration 187, loss = 0.41418659\nIteration 188, loss = 0.41380807\nIteration 189, loss = 0.41361941\nIteration 190, loss = 0.41345939\nIteration 191, loss = 0.41320752\nIteration 192, loss = 0.41316211\nIteration 193, loss = 0.41294116\nIteration 194, loss = 0.41283627\nIteration 195, loss = 0.41281803\nIteration 196, loss = 0.41252444\nIteration 197, loss = 0.41227496\nIteration 198, loss = 0.41215980\nIteration 199, loss = 0.41202066\nIteration 200, loss = 0.41187958\nIteration 1, loss = 0.75925580\nIteration 2, loss = 0.71274133\nIteration 3, loss = 0.67284115\nIteration 4, loss = 0.63924087\nIteration 5, loss = 0.61040600\nIteration 6, loss = 0.58464224\nIteration 7, loss = 0.56405912\nIteration 8, loss = 0.54508177\nIteration 9, loss = 0.52817072\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\nIteration 10, loss = 0.51336129\nIteration 11, loss = 0.50062726\nIteration 12, loss = 0.48909053\nIteration 13, loss = 0.47921894\nIteration 14, loss = 0.47016732\nIteration 15, loss = 0.46260794\nIteration 16, loss = 0.45634034\nIteration 17, loss = 0.45074090\nIteration 18, loss = 0.44650673\nIteration 19, loss = 0.44231222\nIteration 20, loss = 0.43847968\nIteration 21, loss = 0.43584833\nIteration 22, loss = 0.43333389\nIteration 23, loss = 0.43114110\nIteration 24, loss = 0.42953874\nIteration 25, loss = 0.42815390\nIteration 26, loss = 0.42688468\nIteration 27, loss = 0.42572668\nIteration 28, loss = 0.42504230\nIteration 29, loss = 0.42410608\nIteration 30, loss = 0.42355713\nIteration 31, loss = 0.42308607\nIteration 32, loss = 0.42256403\nIteration 33, loss = 0.42241425\nIteration 34, loss = 0.42177924\nIteration 35, loss = 0.42156506\nIteration 36, loss = 0.42114533\nIteration 37, loss = 0.42099101\nIteration 38, loss = 0.42066656\nIteration 39, loss = 0.42032083\nIteration 40, loss = 0.42022289\nIteration 41, loss = 0.41994678\nIteration 42, loss = 0.41979640\nIteration 43, loss = 0.41946204\nIteration 44, loss = 0.41949628\nIteration 45, loss = 0.41914328\nIteration 46, loss = 0.41892023\nIteration 47, loss = 0.41871969\nIteration 48, loss = 0.41864402\nIteration 49, loss = 0.41841531\nIteration 50, loss = 0.41825405\nIteration 51, loss = 0.41812041\nIteration 52, loss = 0.41801237\nIteration 53, loss = 0.41775094\nIteration 54, loss = 0.41756304\nIteration 55, loss = 0.41741925\nIteration 56, loss = 0.41736088\nIteration 57, loss = 0.41725878\nIteration 58, loss = 0.41704912\nIteration 59, loss = 0.41682713\nIteration 60, loss = 0.41672103\nIteration 61, loss = 0.41656511\nIteration 62, loss = 0.41643321\nIteration 63, loss = 0.41626486\nIteration 64, loss = 0.41618180\nIteration 65, loss = 0.41597012\nIteration 66, loss = 0.41595250\nIteration 67, loss = 0.41587818\nIteration 68, loss = 0.41562745\nIteration 69, loss = 0.41540926\nIteration 70, loss = 0.41543148\nIteration 71, loss = 0.41515984\nIteration 72, loss = 0.41504211\nIteration 73, loss = 0.41484086\nIteration 74, loss = 0.41474301\nIteration 75, loss = 0.41455225\nIteration 76, loss = 0.41459528\nIteration 77, loss = 0.41422415\nIteration 78, loss = 0.41410077\nIteration 79, loss = 0.41397740\nIteration 80, loss = 0.41392502\nIteration 81, loss = 0.41376251\nIteration 82, loss = 0.41363789\nIteration 83, loss = 0.41345589\nIteration 84, loss = 0.41331969\nIteration 85, loss = 0.41332718\nIteration 86, loss = 0.41316897\nIteration 87, loss = 0.41309114\nIteration 88, loss = 0.41275448\nIteration 89, loss = 0.41263294\nIteration 90, loss = 0.41261538\nIteration 91, loss = 0.41233817\nIteration 92, loss = 0.41254134\nIteration 93, loss = 0.41211903\nIteration 94, loss = 0.41239059\nIteration 95, loss = 0.41180218\nIteration 96, loss = 0.41160738\nIteration 97, loss = 0.41148594\nIteration 98, loss = 0.41128848\nIteration 99, loss = 0.41119934\nIteration 100, loss = 0.41101113\nIteration 101, loss = 0.41120389\nIteration 102, loss = 0.41080213\nIteration 103, loss = 0.41062142\nIteration 104, loss = 0.41060648\nIteration 105, loss = 0.41032792\nIteration 106, loss = 0.41031351\nIteration 107, loss = 0.41009344\nIteration 108, loss = 0.40992550\nIteration 109, loss = 0.40977983\nIteration 110, loss = 0.40958057\nIteration 111, loss = 0.40948071\nIteration 112, loss = 0.40940772\nIteration 113, loss = 0.40913886\nIteration 114, loss = 0.40906841\nIteration 115, loss = 0.40886924\nIteration 116, loss = 0.40862454\nIteration 117, loss = 0.40849465\nIteration 118, loss = 0.40838730\nIteration 119, loss = 0.40839855\nIteration 120, loss = 0.40823567\nIteration 121, loss = 0.40798647\nIteration 122, loss = 0.40783871\nIteration 123, loss = 0.40759267\nIteration 124, loss = 0.40757465\nIteration 125, loss = 0.40744161\nIteration 126, loss = 0.40716898\nIteration 127, loss = 0.40696921\nIteration 128, loss = 0.40687113\nIteration 129, loss = 0.40677540\nIteration 130, loss = 0.40659737\nIteration 131, loss = 0.40636099\nIteration 132, loss = 0.40627231\nIteration 133, loss = 0.40610151\nIteration 134, loss = 0.40594270\nIteration 135, loss = 0.40566150\nIteration 136, loss = 0.40590785\nIteration 137, loss = 0.40534965\nIteration 138, loss = 0.40523999\nIteration 139, loss = 0.40523534\nIteration 140, loss = 0.40492602\nIteration 141, loss = 0.40477904\nIteration 142, loss = 0.40456934\nIteration 143, loss = 0.40442457\nIteration 144, loss = 0.40436259\nIteration 145, loss = 0.40421737\nIteration 146, loss = 0.40398994\nIteration 147, loss = 0.40383132\nIteration 148, loss = 0.40373285\nIteration 149, loss = 0.40338958\nIteration 150, loss = 0.40321517\nIteration 151, loss = 0.40308185\nIteration 152, loss = 0.40296181\nIteration 153, loss = 0.40330520\nIteration 154, loss = 0.40271075\nIteration 155, loss = 0.40226210\nIteration 156, loss = 0.40230115\nIteration 157, loss = 0.40207715\nIteration 158, loss = 0.40187453\nIteration 159, loss = 0.40170969\nIteration 160, loss = 0.40162651\nIteration 161, loss = 0.40141410\nIteration 162, loss = 0.40128643\nIteration 163, loss = 0.40102697\nIteration 164, loss = 0.40099237\nIteration 165, loss = 0.40074496\nIteration 166, loss = 0.40053050\nIteration 167, loss = 0.40022328\nIteration 168, loss = 0.40011570\nIteration 169, loss = 0.39992013\nIteration 170, loss = 0.39989971\nIteration 171, loss = 0.39959231\nIteration 172, loss = 0.39959776\nIteration 173, loss = 0.39937254\nIteration 174, loss = 0.39916508\nIteration 175, loss = 0.39891643\nIteration 176, loss = 0.39876338\nIteration 177, loss = 0.39845717\nIteration 178, loss = 0.39852260\nIteration 179, loss = 0.39816377\nIteration 180, loss = 0.39793326\nIteration 181, loss = 0.39770335\nIteration 182, loss = 0.39757392\nIteration 183, loss = 0.39727938\nIteration 184, loss = 0.39717359\nIteration 185, loss = 0.39721291\nIteration 186, loss = 0.39690293\nIteration 187, loss = 0.39672700\nIteration 188, loss = 0.39650343\nIteration 189, loss = 0.39633308\nIteration 190, loss = 0.39604221\nIteration 191, loss = 0.39592522\nIteration 192, loss = 0.39573477\nIteration 193, loss = 0.39541271\nIteration 194, loss = 0.39546959\nIteration 195, loss = 0.39526025\nIteration 196, loss = 0.39495133\nIteration 197, loss = 0.39502069\nIteration 198, loss = 0.39462146\nIteration 199, loss = 0.39444036\nIteration 200, loss = 0.39405456\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\nIteration 1, loss = 0.76162014\nIteration 2, loss = 0.71395006\nIteration 3, loss = 0.67510773\nIteration 4, loss = 0.64121698\nIteration 5, loss = 0.61162532\nIteration 6, loss = 0.58647122\nIteration 7, loss = 0.56515843\nIteration 8, loss = 0.54568044\nIteration 9, loss = 0.52848800\nIteration 10, loss = 0.51329764\nIteration 11, loss = 0.50043738\nIteration 12, loss = 0.48863707\nIteration 13, loss = 0.47855389\nIteration 14, loss = 0.46917606\nIteration 15, loss = 0.46158790\nIteration 16, loss = 0.45486821\nIteration 17, loss = 0.44929371\nIteration 18, loss = 0.44473472\nIteration 19, loss = 0.44000009\nIteration 20, loss = 0.43660628\nIteration 21, loss = 0.43344395\nIteration 22, loss = 0.43085293\nIteration 23, loss = 0.42841577\nIteration 24, loss = 0.42659647\nIteration 25, loss = 0.42514503\nIteration 26, loss = 0.42367574\nIteration 27, loss = 0.42251075\nIteration 28, loss = 0.42168396\nIteration 29, loss = 0.42080892\nIteration 30, loss = 0.42002364\nIteration 31, loss = 0.41961428\nIteration 32, loss = 0.41913147\nIteration 33, loss = 0.41887045\nIteration 34, loss = 0.41824601\nIteration 35, loss = 0.41784690\nIteration 36, loss = 0.41772247\nIteration 37, loss = 0.41740640\nIteration 38, loss = 0.41705388\nIteration 39, loss = 0.41684399\nIteration 40, loss = 0.41677747\nIteration 41, loss = 0.41648069\nIteration 42, loss = 0.41634041\nIteration 43, loss = 0.41613864\nIteration 44, loss = 0.41607032\nIteration 45, loss = 0.41577224\nIteration 46, loss = 0.41562564\nIteration 47, loss = 0.41544361\nIteration 48, loss = 0.41534689\nIteration 49, loss = 0.41520264\nIteration 50, loss = 0.41501851\nIteration 51, loss = 0.41490496\nIteration 52, loss = 0.41483717\nIteration 53, loss = 0.41463435\nIteration 54, loss = 0.41448395\nIteration 55, loss = 0.41435733\nIteration 56, loss = 0.41422265\nIteration 57, loss = 0.41415416\nIteration 58, loss = 0.41409455\nIteration 59, loss = 0.41385033\nIteration 60, loss = 0.41369608\nIteration 61, loss = 0.41364965\nIteration 62, loss = 0.41348600\nIteration 63, loss = 0.41344461\nIteration 64, loss = 0.41339266\nIteration 65, loss = 0.41318384\nIteration 66, loss = 0.41306960\nIteration 67, loss = 0.41291770\nIteration 68, loss = 0.41274353\nIteration 69, loss = 0.41262646\nIteration 70, loss = 0.41260336\nIteration 71, loss = 0.41241218\nIteration 72, loss = 0.41228095\nIteration 73, loss = 0.41206310\nIteration 74, loss = 0.41204438\nIteration 75, loss = 0.41187849\nIteration 76, loss = 0.41178018\nIteration 77, loss = 0.41165065\nIteration 78, loss = 0.41148491\nIteration 79, loss = 0.41132729\nIteration 80, loss = 0.41124716\nIteration 81, loss = 0.41110591\nIteration 82, loss = 0.41097227\nIteration 83, loss = 0.41082922\nIteration 84, loss = 0.41074306\nIteration 85, loss = 0.41073770\nIteration 86, loss = 0.41043923\nIteration 87, loss = 0.41053682\nIteration 88, loss = 0.41031485\nIteration 89, loss = 0.41018276\nIteration 90, loss = 0.41013977\nIteration 91, loss = 0.40986338\nIteration 92, loss = 0.40999788\nIteration 93, loss = 0.40968275\nIteration 94, loss = 0.40962614\nIteration 95, loss = 0.40935542\nIteration 96, loss = 0.40924826\nIteration 97, loss = 0.40924337\nIteration 98, loss = 0.40899168\nIteration 99, loss = 0.40893600\nIteration 100, loss = 0.40864166\nIteration 101, loss = 0.40885910\nIteration 102, loss = 0.40859987\nIteration 103, loss = 0.40836482\nIteration 104, loss = 0.40834533\nIteration 105, loss = 0.40805694\nIteration 106, loss = 0.40798833\nIteration 107, loss = 0.40789748\nIteration 108, loss = 0.40785903\nIteration 109, loss = 0.40772875\nIteration 110, loss = 0.40751156\nIteration 111, loss = 0.40726331\nIteration 112, loss = 0.40721151\nIteration 113, loss = 0.40705374\nIteration 114, loss = 0.40697341\nIteration 115, loss = 0.40682594\nIteration 116, loss = 0.40661627\nIteration 117, loss = 0.40649390\nIteration 118, loss = 0.40645542\nIteration 119, loss = 0.40641639\nIteration 120, loss = 0.40618601\nIteration 121, loss = 0.40608514\nIteration 122, loss = 0.40592832\nIteration 123, loss = 0.40567719\nIteration 124, loss = 0.40563873\nIteration 125, loss = 0.40553267\nIteration 126, loss = 0.40535461\nIteration 127, loss = 0.40523251\nIteration 128, loss = 0.40503912\nIteration 129, loss = 0.40492429\nIteration 130, loss = 0.40485407\nIteration 131, loss = 0.40457422\nIteration 132, loss = 0.40453176\nIteration 133, loss = 0.40441106\nIteration 134, loss = 0.40423741\nIteration 135, loss = 0.40404837\nIteration 136, loss = 0.40398508\nIteration 137, loss = 0.40407400\nIteration 138, loss = 0.40377217\nIteration 139, loss = 0.40363388\nIteration 140, loss = 0.40343406\nIteration 141, loss = 0.40330334\nIteration 142, loss = 0.40304042\nIteration 143, loss = 0.40284689\nIteration 144, loss = 0.40285986\nIteration 145, loss = 0.40274835\nIteration 146, loss = 0.40266281\nIteration 147, loss = 0.40233181\nIteration 148, loss = 0.40228323\nIteration 149, loss = 0.40201160\nIteration 150, loss = 0.40186503\nIteration 151, loss = 0.40171049\nIteration 152, loss = 0.40175858\nIteration 153, loss = 0.40185728\nIteration 154, loss = 0.40129325\nIteration 155, loss = 0.40110511\nIteration 156, loss = 0.40104225\nIteration 157, loss = 0.40080889\nIteration 158, loss = 0.40066116\nIteration 159, loss = 0.40049427\nIteration 160, loss = 0.40042652\nIteration 161, loss = 0.40029959\nIteration 162, loss = 0.40017089\nIteration 163, loss = 0.39996527\nIteration 164, loss = 0.39979336\nIteration 165, loss = 0.39955392\nIteration 166, loss = 0.39946992\nIteration 167, loss = 0.39922656\nIteration 168, loss = 0.39924487\nIteration 169, loss = 0.39899522\nIteration 170, loss = 0.39889903\nIteration 171, loss = 0.39859018\nIteration 172, loss = 0.39850296\nIteration 173, loss = 0.39852792\nIteration 174, loss = 0.39821081\nIteration 175, loss = 0.39813231\nIteration 176, loss = 0.39785049\nIteration 177, loss = 0.39769413\nIteration 178, loss = 0.39756950\nIteration 179, loss = 0.39740728\nIteration 180, loss = 0.39712439\nIteration 181, loss = 0.39696699\nIteration 182, loss = 0.39681519\nIteration 183, loss = 0.39657970\nIteration 184, loss = 0.39642274\nIteration 185, loss = 0.39636589\nIteration 186, loss = 0.39626040\nIteration 187, loss = 0.39591510\nIteration 188, loss = 0.39584586\nIteration 189, loss = 0.39569323\nIteration 190, loss = 0.39553429\nIteration 191, loss = 0.39522100\nIteration 192, loss = 0.39529325\nIteration 193, loss = 0.39479157\nIteration 194, loss = 0.39480780\nIteration 195, loss = 0.39478172\nIteration 196, loss = 0.39431907\nIteration 197, loss = 0.39425127\nIteration 198, loss = 0.39410598\nIteration 199, loss = 0.39399821\nIteration 200, loss = 0.39359271\nIteration 1, loss = 0.75442427\nIteration 2, loss = 0.70803020\nIteration 3, loss = 0.66862049\nIteration 4, loss = 0.63582109\nIteration 5, loss = 0.60755083\nIteration 6, loss = 0.58374915\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\nIteration 7, loss = 0.56431470\nIteration 8, loss = 0.54643150\nIteration 9, loss = 0.53126811\nIteration 10, loss = 0.51786176\nIteration 11, loss = 0.50649546\nIteration 12, loss = 0.49679102\nIteration 13, loss = 0.48823918\nIteration 14, loss = 0.48031866\nIteration 15, loss = 0.47425185\nIteration 16, loss = 0.46874799\nIteration 17, loss = 0.46482924\nIteration 18, loss = 0.46079837\nIteration 19, loss = 0.45728654\nIteration 20, loss = 0.45507408\nIteration 21, loss = 0.45291126\nIteration 22, loss = 0.45088138\nIteration 23, loss = 0.44940744\nIteration 24, loss = 0.44822869\nIteration 25, loss = 0.44722240\nIteration 26, loss = 0.44629803\nIteration 27, loss = 0.44561259\nIteration 28, loss = 0.44518183\nIteration 29, loss = 0.44458657\nIteration 30, loss = 0.44410195\nIteration 31, loss = 0.44380084\nIteration 32, loss = 0.44352698\nIteration 33, loss = 0.44329762\nIteration 34, loss = 0.44295503\nIteration 35, loss = 0.44264666\nIteration 36, loss = 0.44256458\nIteration 37, loss = 0.44233219\nIteration 38, loss = 0.44205944\nIteration 39, loss = 0.44184466\nIteration 40, loss = 0.44179700\nIteration 41, loss = 0.44154258\nIteration 42, loss = 0.44139890\nIteration 43, loss = 0.44118367\nIteration 44, loss = 0.44107569\nIteration 45, loss = 0.44086260\nIteration 46, loss = 0.44071880\nIteration 47, loss = 0.44049257\nIteration 48, loss = 0.44037084\nIteration 49, loss = 0.44025909\nIteration 50, loss = 0.44018186\nIteration 51, loss = 0.43993274\nIteration 52, loss = 0.43980323\nIteration 53, loss = 0.43968179\nIteration 54, loss = 0.43943121\nIteration 55, loss = 0.43932192\nIteration 56, loss = 0.43907868\nIteration 57, loss = 0.43897596\nIteration 58, loss = 0.43913512\nIteration 59, loss = 0.43867992\nIteration 60, loss = 0.43851774\nIteration 61, loss = 0.43841581\nIteration 62, loss = 0.43819191\nIteration 63, loss = 0.43817790\nIteration 64, loss = 0.43803119\nIteration 65, loss = 0.43790882\nIteration 66, loss = 0.43771400\nIteration 67, loss = 0.43758214\nIteration 68, loss = 0.43744820\nIteration 69, loss = 0.43727883\nIteration 70, loss = 0.43725240\nIteration 71, loss = 0.43693794\nIteration 72, loss = 0.43683248\nIteration 73, loss = 0.43660157\nIteration 74, loss = 0.43654354\nIteration 75, loss = 0.43627440\nIteration 76, loss = 0.43621073\nIteration 77, loss = 0.43612404\nIteration 78, loss = 0.43602670\nIteration 79, loss = 0.43570727\nIteration 80, loss = 0.43560422\nIteration 81, loss = 0.43545866\nIteration 82, loss = 0.43526386\nIteration 83, loss = 0.43515149\nIteration 84, loss = 0.43505209\nIteration 85, loss = 0.43490346\nIteration 86, loss = 0.43467696\nIteration 87, loss = 0.43501318\nIteration 88, loss = 0.43455529\nIteration 89, loss = 0.43429149\nIteration 90, loss = 0.43409804\nIteration 91, loss = 0.43394665\nIteration 92, loss = 0.43396080\nIteration 93, loss = 0.43363639\nIteration 94, loss = 0.43354060\nIteration 95, loss = 0.43333802\nIteration 96, loss = 0.43323735\nIteration 97, loss = 0.43313029\nIteration 98, loss = 0.43285165\nIteration 99, loss = 0.43273329\nIteration 100, loss = 0.43246640\nIteration 101, loss = 0.43277102\nIteration 102, loss = 0.43233421\nIteration 103, loss = 0.43224102\nIteration 104, loss = 0.43201897\nIteration 105, loss = 0.43184732\nIteration 106, loss = 0.43159943\nIteration 107, loss = 0.43156382\nIteration 108, loss = 0.43146918\nIteration 109, loss = 0.43135155\nIteration 110, loss = 0.43116562\nIteration 111, loss = 0.43078771\nIteration 112, loss = 0.43077023\nIteration 113, loss = 0.43046701\nIteration 114, loss = 0.43032309\nIteration 115, loss = 0.43028046\nIteration 116, loss = 0.43008150\nIteration 117, loss = 0.42988055\nIteration 118, loss = 0.42975883\nIteration 119, loss = 0.42972280\nIteration 120, loss = 0.42962508\nIteration 121, loss = 0.42923943\nIteration 122, loss = 0.42912292\nIteration 123, loss = 0.42894796\nIteration 124, loss = 0.42887856\nIteration 125, loss = 0.42861032\nIteration 126, loss = 0.42868583\nIteration 127, loss = 0.42821252\nIteration 128, loss = 0.42811275\nIteration 129, loss = 0.42786016\nIteration 130, loss = 0.42775674\nIteration 131, loss = 0.42757188\nIteration 132, loss = 0.42740187\nIteration 133, loss = 0.42737500\nIteration 134, loss = 0.42705772\nIteration 135, loss = 0.42696462\nIteration 136, loss = 0.42678116\nIteration 137, loss = 0.42666018\nIteration 138, loss = 0.42623433\nIteration 139, loss = 0.42634011\nIteration 140, loss = 0.42609205\nIteration 141, loss = 0.42592171\nIteration 142, loss = 0.42567153\nIteration 143, loss = 0.42558842\nIteration 144, loss = 0.42542322\nIteration 145, loss = 0.42520055\nIteration 146, loss = 0.42493076\nIteration 147, loss = 0.42487340\nIteration 148, loss = 0.42461854\nIteration 149, loss = 0.42438149\nIteration 150, loss = 0.42428471\nIteration 151, loss = 0.42407388\nIteration 152, loss = 0.42401548\nIteration 153, loss = 0.42407066\nIteration 154, loss = 0.42350426\nIteration 155, loss = 0.42353166\nIteration 156, loss = 0.42312833\nIteration 157, loss = 0.42300443\nIteration 158, loss = 0.42288069\nIteration 159, loss = 0.42261914\nIteration 160, loss = 0.42242586\nIteration 161, loss = 0.42218757\nIteration 162, loss = 0.42198335\nIteration 163, loss = 0.42187465\nIteration 164, loss = 0.42170568\nIteration 165, loss = 0.42144714\nIteration 166, loss = 0.42137737\nIteration 167, loss = 0.42113434\nIteration 168, loss = 0.42095290\nIteration 169, loss = 0.42080987\nIteration 170, loss = 0.42063489\nIteration 171, loss = 0.42025767\nIteration 172, loss = 0.42010644\nIteration 173, loss = 0.41997494\nIteration 174, loss = 0.41985390\nIteration 175, loss = 0.41971105\nIteration 176, loss = 0.41946506\nIteration 177, loss = 0.41917772\nIteration 178, loss = 0.41894615\nIteration 179, loss = 0.41884738\nIteration 180, loss = 0.41860682\nIteration 181, loss = 0.41834385\nIteration 182, loss = 0.41820518\nIteration 183, loss = 0.41806751\nIteration 184, loss = 0.41796441\nIteration 185, loss = 0.41782257\nIteration 186, loss = 0.41752844\nIteration 187, loss = 0.41723619\nIteration 188, loss = 0.41700611\nIteration 189, loss = 0.41682847\nIteration 190, loss = 0.41657302\nIteration 191, loss = 0.41642783\nIteration 192, loss = 0.41638565\nIteration 193, loss = 0.41593795\nIteration 194, loss = 0.41588253\nIteration 195, loss = 0.41582744\nIteration 196, loss = 0.41537603\nIteration 197, loss = 0.41547250\nIteration 198, loss = 0.41518620\nIteration 199, loss = 0.41506482\nIteration 200, loss = 0.41488463\nIteration 1, loss = 0.75065251\nIteration 2, loss = 0.70190708\nIteration 3, loss = 0.65722314\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\nIteration 4, loss = 0.62139734\nIteration 5, loss = 0.59159805\nIteration 6, loss = 0.56586290\nIteration 7, loss = 0.54358053\nIteration 8, loss = 0.52579304\nIteration 9, loss = 0.50911544\nIteration 10, loss = 0.49552867\nIteration 11, loss = 0.48340195\nIteration 12, loss = 0.47317948\nIteration 13, loss = 0.46307054\nIteration 14, loss = 0.45520104\nIteration 15, loss = 0.44811142\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"start_time":"2021-01-30T11:27:31.314Z"},"cell_id":"00013-ce689dd9-bd75-4ca8-b58c-d8c954b41a10","deepnote_to_be_reexecuted":false,"execution_millis":33975,"execution_start":1612007312153,"source_hash":"78e92364","deepnote_cell_type":"code"},"source":"tuned_parameters = [{'solver': ['lbfgs'], 'alpha': list(10.0 ** -np.arange(1, 7)), 'activation': ['tanh'],\n                     'random_state': [0]}]\n\nclf = GridSearchCV(MLPClassifier(), tuned_parameters)\nclf.fit(X_train_norm, y_train)\n\nprint(\"Best parameters set found on development set:\")\nprint()\nprint(clf.best_params_)\n\n\nprint(\"Detailed classification report:\")\nprint()\nprint(\"The model is trained on the full development set.\")\nprint(\"The scores are computed on the full evaluation set.\")\nprint()\ny_true, y_pred = y_test, clf.predict(X_test_norm)\nprint(classification_report(y_true, y_pred))\nprint()\n","execution_count":null,"outputs":[{"name":"stderr","text":"/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\n  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-458ad9794a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \"\"\"\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[0;32m--> 405\u001b[0;31m                             intercept_grads, layer_units)\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[1;32m    497\u001b[0m                     \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 },\n\u001b[0;32m--> 499\u001b[0;31m                 args=(X, y, activations, deltas, coef_grads, intercept_grads))\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_optimize_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 620\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    621\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[0;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0;32m--> 209\u001b[0;31m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    286\u001b[0m             self._compute_loss_grad(\n\u001b[1;32m    287\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 intercept_grads)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_compute_loss_grad\u001b[0;34m(self, layer, n_samples, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \"\"\"\n\u001b[1;32m    158\u001b[0m         coef_grads[layer] = safe_sparse_dot(activations[layer].T,\n\u001b[0;32m--> 159\u001b[0;31m                                             deltas[layer])\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mcoef_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mcoef_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}],"nbformat":4,"nbformat_minor":2,"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"6ed92db1-0446-4d66-be0b-3e2d2680e1f7","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}}}