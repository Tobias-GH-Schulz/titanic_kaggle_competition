{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T21:52:37.944436Z",
     "start_time": "2021-01-30T21:52:35.687800Z"
    },
    "cell_id": "00000-f3de8d9a-9007-4fe1-9480-8e83b4b1ae26",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1612023666168,
    "source_hash": "b60bd3a1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('Train_clean.csv')\n",
    "data  = data.drop(\"not_alone\", axis=1)\n",
    "#test  = test.drop(\"not_alone\", axis=1)\n",
    "\n",
    "data  = data.drop(\"Parch\", axis=1)\n",
    "#test  = test.drop(\"Parch\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T21:52:42.384229Z",
     "start_time": "2021-01-30T21:52:42.379108Z"
    },
    "cell_id": "00003-607f4d20-67e1-44f0-81d6-a37a24715feb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1612023670468,
    "source_hash": "9a7fe698",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Survived', \"Unnamed: 0\"], axis=1)\n",
    "y = data.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T21:52:45.059274Z",
     "start_time": "2021-01-30T21:52:45.050379Z"
    },
    "cell_id": "00004-68e192ee-1a06-408d-a803-83143f5eb94e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1612023673140,
    "source_hash": "580fdd9e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-001f2270-f8e2-467e-9db9-6acf255ac729",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T14:10:34.471039Z",
     "start_time": "2021-01-30T14:10:34.265419Z"
    },
    "cell_id": "00003-ef1f89b6-ece9-42e9-93f7-b3e651cbf628",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 543,
    "execution_start": 1612023679181,
    "source_hash": "2662f3e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.48 %\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(criterion = \"gini\", \n",
    "                                       min_samples_leaf = 1, \n",
    "                                       min_samples_split = 10,   \n",
    "                                       n_estimators=100, \n",
    "                                       max_features='auto', \n",
    "                                       oob_score=True, \n",
    "                                       random_state=1, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train_norm, y_train)\n",
    "Y_prediction = random_forest.predict(X_test_norm)\n",
    "\n",
    "random_forest.score(X_train_norm, y_train)\n",
    "\n",
    "acc_random_forest = round(random_forest.score(X_train_norm, y_train) * 100, 2)\n",
    "print(round(acc_random_forest,2,), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T14:10:39.893208Z",
     "start_time": "2021-01-30T14:10:39.873663Z"
    },
    "cell_id": "00004-a2e932d2-8d95-4472-86ba-000556c5c19e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 34,
    "execution_start": 1612019105292,
    "scrolled": true,
    "source_hash": "f805a6c7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "column_count": 1,
       "columns": [
        {
         "dtype": "float64",
         "name": "importance",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.0565,
            "bin_start": 0.033,
            "count": 2
           },
           {
            "bin_end": 0.08,
            "bin_start": 0.0565,
            "count": 3
           },
           {
            "bin_end": 0.10350000000000001,
            "bin_start": 0.08,
            "count": 0
           },
           {
            "bin_end": 0.127,
            "bin_start": 0.10350000000000001,
            "count": 1
           },
           {
            "bin_end": 0.1505,
            "bin_start": 0.127,
            "count": 1
           },
           {
            "bin_end": 0.17400000000000002,
            "bin_start": 0.1505,
            "count": 0
           },
           {
            "bin_end": 0.1975,
            "bin_start": 0.17400000000000002,
            "count": 0
           },
           {
            "bin_end": 0.221,
            "bin_start": 0.1975,
            "count": 1
           },
           {
            "bin_end": 0.2445,
            "bin_start": 0.221,
            "count": 0
           },
           {
            "bin_end": 0.268,
            "bin_start": 0.2445,
            "count": 1
           }
          ],
          "max": 0.268,
          "min": 0.033,
          "nan_count": 0,
          "unique_count": 9
         }
        },
        {
         "dtype": "object",
         "name": "_deepnote_index_column"
        }
       ],
       "row_count": 9,
       "rows_bottom": null,
       "rows_top": [
        {
         "_deepnote_index_column": "Fare",
         "importance": 0.268
        },
        {
         "_deepnote_index_column": "Title",
         "importance": 0.203
        },
        {
         "_deepnote_index_column": "Sex",
         "importance": 0.148
        },
        {
         "_deepnote_index_column": "Age",
         "importance": 0.11
        },
        {
         "_deepnote_index_column": "relatives",
         "importance": 0.067
        },
        {
         "_deepnote_index_column": "Pclass",
         "importance": 0.063
        },
        {
         "_deepnote_index_column": "Deck",
         "importance": 0.059
        },
        {
         "_deepnote_index_column": "SibSp",
         "importance": 0.05
        },
        {
         "_deepnote_index_column": "Embarked",
         "importance": 0.033
        }
       ]
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relatives</th>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deck</th>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           importance\n",
       "feature              \n",
       "Fare            0.268\n",
       "Title           0.203\n",
       "Sex             0.148\n",
       "Age             0.110\n",
       "relatives       0.067\n",
       "Pclass          0.063\n",
       "Deck            0.059\n",
       "SibSp           0.050\n",
       "Embarked        0.033"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T14:10:43.785937Z",
     "start_time": "2021-01-30T14:10:43.641832Z"
    },
    "cell_id": "00005-e2e10778-e4da-4abd-a753-79237fb930bf",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1079,
    "execution_start": 1612019107837,
    "scrolled": false,
    "source_hash": "3c2b6713"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/backend/resource_tracker.py:120: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some folders/sempahores might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEvCAYAAABL4wrUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgXUlEQVR4nO3de5xVdb3/8debQcUUTXQylLvhrUDgDGNJpqYi/Sr4lSjeeohH42eGdfLkiX6dn55DN7taxyyhNNOjiZff6UeKxzvlJRUEgRAvgKSYpeKNTJSBz++PtWbYbAdmw+y91/Dl/Xw85sFe37XXXp+ZYd577e/6ru9SRGBmZunqVnQBZmZWWw56M7PEOejNzBLnoDczS5yD3swscQ56M7PEdS+6gHJ77bVXDBgwoOgyzMy2KY888shLEdHY3rouF/QDBgxg7ty5RZdhZrZNkfSnTa1z142ZWeIc9GZmiXPQm5klrsv10ZvZtmXt2rWsXLmSNWvWFF3KdqFHjx706dOHHXbYoeJtHPRm1ikrV66kZ8+eDBgwAElFl5O0iGDVqlWsXLmSgQMHVrydu27MrFPWrFnDnnvu6ZCvA0nsueeeW/zpyUFvZp3mkK+frflZO+jNbJt32GGH1XV/K1as4Nprr63rPjtjm+2jHzDllqq8zoqLPl6V1zGzTLX+NltV8jf6wAMPVHWfm9PS0tIW9Kecckrd9tsZPqI3s23errvuCsDs2bM54ogjGDduHIMGDWLKlClcc801NDc3M2TIEJYtWwbAxIkTOfvss2lqamL//ffn5ptvBrLzDWeccQZDhgxh+PDh3HPPPQBceeWVjB07lo9+9KMcffTRTJkyhXvvvZdhw4Zx8cUXs2LFCg4//HBGjBjBiBEj2t54Zs+ezZFHHsn48eM58MADOfXUU2m9q9+cOXM47LDDOOSQQ2hubmb16tWsW7eO888/n5EjRzJ06FCmTZtWlZ/PNntEb2bWngULFrBkyRJ69erFoEGDOOuss3j44Yf58Y9/zCWXXMKPfvQjIOt+efjhh1m2bBlHHXUUS5cu5dJLL0USixYt4vHHH2f06NE8+eSTAMybN4+FCxfSq1cvZs+ezfe///22N4i///3v3HHHHfTo0YOnnnqKk08+uW0ql/nz57N48WL22WcfRo0axf33309zczMTJkxgxowZjBw5ktdff52dd96Zyy+/nN133505c+bw1ltvMWrUKEaPHr1FI2za46A3s6SMHDmS3r17A7DffvsxevRoAIYMGdJ2hA5w4okn0q1bNwYPHsygQYN4/PHHue+++zj33HMBOPDAA+nfv39b0B977LH06tWr3X2uXbuWyZMn8+ijj9LQ0NC2DUBzczN9+vQBYNiwYaxYsYLdd9+d3r17M3LkSAB22203AG6//XYWLlzIjTfeCMBrr73GU0895aA3Myu10047tT3u1q1b23K3bt1oaWlpW1c+eqWj0Sy77LLLJtddfPHF7L333ixYsID169fTo0ePdutpaGjYqIZyEcEll1zCcccdt9latpT76M1su3TDDTewfv16li1bxvLlyznggAM4/PDDueaaawB48skneeaZZzjggAPesW3Pnj1ZvXp12/Jrr71G79696datG1dffTXr1q3b7L4POOAAnn/+eebMmQPA6tWraWlp4bjjjuNnP/sZa9eubavhjTfe6PT36iN6M9su9evXj+bmZl5//XUuu+wyevTowTnnnMPnPvc5hgwZQvfu3bnyyis3OiJvNXToUBoaGjjkkEOYOHEi55xzDscffzxXXXUVY8aM2ezRP8COO+7IjBkzOPfcc3nzzTfZeeedufPOOznrrLNYsWIFI0aMICJobGzkN7/5Tae/V7WeAe4qmpqaopL56D280qxrWLJkCQcddFDRZWyRiRMn8olPfILx48cXXcpWae9nLumRiGhq7/nuujEzS5y7bsxsu3PllVcWXUJdVXREL2mMpCckLZU0pZ3150l6TNJCSXdJ6l+ybp2kR/OvmdUs3szMOtbhEb2kBuBS4FhgJTBH0syIeKzkafOBpoj4u6TPAd8FJuTr3oyIYdUt28y6kojwxGZ1sjXnVSs5om8GlkbE8oh4G7gOGFe243si4u/54oNAny2uxMy2ST169GDVqlVbFUC2ZVrnoy8dp1+JSvro9wWeLVleCRy6meefCdxastxD0lygBbgoIn6zRRWaWZfWp08fVq5cyYsvvlh0KduF1jtMbYmqnoyVdBrQBBxR0tw/Ip6TNAi4W9KiiFhWtt0kYBJkY1vNbNuxww47dPoSfautSrpungP6liz3yds2IukY4GvA2Ih4q7U9Ip7L/10OzAaGl28bEdMjoikimhobG7foGzAzs82rJOjnAIMlDZS0I3ASsNHoGUnDgWlkIf9CSfseknbKH+8FjAJKT+KamVmNddh1ExEtkiYDtwENwBURsVjSVGBuRMwEvgfsCtyQn3l/JiLGAgcB0yStJ3tTuahstI6ZmdVYRX30ETELmFXWdkHJ42M2sd0DwJDOFGhmZp3jKRDMzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS1xFQS9pjKQnJC2VNKWd9edJekzSQkl3Sepfsu50SU/lX6dXs3gzM+tYh0EvqQG4FPgYcDBwsqSDy542H2iKiKHAjcB38217ARcChwLNwIWS9qhe+WZm1pHuFTynGVgaEcsBJF0HjAMea31CRNxT8vwHgdPyx8cBd0TEy/m2dwBjgF93vvSuZ8CUW6r2Wisu+njVXsvMtm+VdN3sCzxbsrwyb9uUM4Fbt3JbMzOrskqO6Csm6TSgCThiC7ebBEwC6NevXzVLMjPb7lVyRP8c0LdkuU/ethFJxwBfA8ZGxFtbsm1ETI+IpohoamxsrLR2MzOrQCVBPwcYLGmgpB2Bk4CZpU+QNByYRhbyL5Ssug0YLWmP/CTs6LzNzMzqpMOum4hokTSZLKAbgCsiYrGkqcDciJgJfA/YFbhBEsAzETE2Il6W9HWyNwuAqa0nZs3MrD4q6qOPiFnArLK2C0oeH7OZba8ArtjaAs3MrHN8ZayZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiaso6CWNkfSEpKWSprSz/iOS5klqkTS+bN06SY/mXzOrVbiZmVWme0dPkNQAXAocC6wE5kiaGRGPlTztGWAi8OV2XuLNiBjW+VLNzGxrdBj0QDOwNCKWA0i6DhgHtAV9RKzI162vQY1mZtYJlXTd7As8W7K8Mm+rVA9JcyU9KOl/bklxZmbWeZUc0XdW/4h4TtIg4G5JiyJiWekTJE0CJgH069evDiWZmW0/Kgn654C+Jct98raKRMRz+b/LJc0GhgPLyp4zHZgO0NTUFJW+tnVswJRbqvZaKy76eNVey8zqp5KumznAYEkDJe0InARUNHpG0h6Sdsof7wWMoqRv38zMaq/DoI+IFmAycBuwBLg+IhZLmippLICkkZJWAicA0yQtzjc/CJgraQFwD3BR2WgdMzOrsYr66CNiFjCrrO2CksdzyLp0yrd7ABjSyRrNzKwTfGWsmVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZonrXnQBtv0ZMOWWqr3Wios+XrXXMkuVj+jNzBLnoDczS1xFQS9pjKQnJC2VNKWd9R+RNE9Si6TxZetOl/RU/nV6tQo3M7PKdBj0khqAS4GPAQcDJ0s6uOxpzwATgWvLtu0FXAgcCjQDF0rao/Nlm5lZpSo5om8GlkbE8oh4G7gOGFf6hIhYERELgfVl2x4H3BERL0fEK8AdwJgq1G1mZhWqJOj3BZ4tWV6Zt1WiM9uamVkVdImTsZImSZorae6LL75YdDlmZkmpJOifA/qWLPfJ2ypR0bYRMT0imiKiqbGxscKXNjOzSlQS9HOAwZIGStoROAmYWeHr3waMlrRHfhJ2dN5mZmZ10mHQR0QLMJksoJcA10fEYklTJY0FkDRS0krgBGCapMX5ti8DXyd7s5gDTM3bzMysTiqaAiEiZgGzytouKHk8h6xbpr1trwCu6ESNZmbWCV3iZKyZmdWOg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0tc96ILMOsqBky5pSqvs+Kij1fldcyqxUf0ZmaJc9CbmSXOXTdmXZi7k6wafERvZpY4B72ZWeLcdWNmW6Ra3UngLqV68RG9mVniHPRmZomrKOgljZH0hKSlkqa0s34nSTPy9Q9JGpC3D5D0pqRH86/Lqly/mZl1oMM+ekkNwKXAscBKYI6kmRHxWMnTzgReiYj3SToJ+A4wIV+3LCKGVbdsMzOrVCVH9M3A0ohYHhFvA9cB48qeMw74Vf74RuBoSapemWZmtrUqCfp9gWdLllfmbe0+JyJagNeAPfN1AyXNl/Q7SYd3sl4zM9tCtR5e+TzQLyJWSfoH4DeS3h8Rr5c+SdIkYBJAv379alySmaXGQz43r5Ij+ueAviXLffK2dp8jqTuwO7AqIt6KiFUAEfEIsAzYv3wHETE9IpoioqmxsXHLvwszM9ukSoJ+DjBY0kBJOwInATPLnjMTOD1/PB64OyJCUmN+MhdJg4DBwPLqlG5mZpXosOsmIlokTQZuAxqAKyJisaSpwNyImAlcDlwtaSnwMtmbAcBHgKmS1gLrgbMj4uVafCNmZta+ivroI2IWMKus7YKSx2uAE9rZ7ibgpk7WaGZmneArY83MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8T5nrFmZjXQlSZa8xG9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniKgp6SWMkPSFpqaQp7azfSdKMfP1DkgaUrPtq3v6EpOOqWLuZmVWgw6CX1ABcCnwMOBg4WdLBZU87E3glIt4HXAx8J9/2YOAk4P3AGOCn+euZmVmdVHJE3wwsjYjlEfE2cB0wruw544Bf5Y9vBI6WpLz9uoh4KyKeBpbmr2dmZnVSSdDvCzxbsrwyb2v3ORHRArwG7FnhtmZmVkPdiy4AQNIkYFK++DdJT1TppfcCXtrsvr9TpT1VrsOaoO51dcWaYBv9/bkmoGv+n+qKNUH1fn/9N7WikqB/Duhbstwnb2vvOSsldQd2B1ZVuC0RMR2YXkEtW0TS3IhoqvbrdoZrqlxXrMs1VcY1Va4edVXSdTMHGCxpoKQdyU6uzix7zkzg9PzxeODuiIi8/aR8VM5AYDDwcHVKNzOzSnR4RB8RLZImA7cBDcAVEbFY0lRgbkTMBC4Hrpa0FHiZ7M2A/HnXA48BLcDnI2Jdjb4XMzNrR0V99BExC5hV1nZByeM1wAmb2PabwDc7UWNnVL07qApcU+W6Yl2uqTKuqXI1r0tZD4uZmaXKUyCYmSXOQW9mljgHfY1J2l/SXZL+mC8PlfSvRddlZtuPJINe0oclnZE/bsyHdhbl58BXgbUAEbGQfFRSkSSdWbbcIOnCourJa9hb0uWSbs2XDy6vs6C69pO0U/74SElfkPRu1/SOmqaWLTdIuqaoekrqeK+ksZI+Kem9Bdfy6c191Wq/yQV9HlZfIQtXgB2A/yyuIt4VEeXXDrQUUsnGjpY0S1JvSe8HHgR6FlzTlWTDePfJl58E/qmoYkrcBKyT9D6yERJ9gWuLLalL1tRX0lchm9EW+L/AU0UWJOkssmt3Pk12jc+Dkv6xwJI+mX+dSTYs/dT86xdAzerqElMgVNmngOHAPICI+LOkIgPsJUn7AQEgaTzwfIH1ABARp0iaACwC3gBOiYj7Cy5rr4i4vjUs8ms4usJ1F+vzWj4FXBIRl0ia75re4R+Ba/Lf31HArIj4UbElcT4wPCJWAUjaE3gAuKKIYiKitafhduDgiHg+X+5NdqBTEykG/dsREZJag3WXguv5PNkR14GSngOeBk4rtiSQNBj4ItmR4UHAZyTNj4i/F1jWG/kfYuvv7oNkE+QVba2kk8mu/v5k3rZDgfVAF6pJ0oiSxR8D04D7gd9LGhER84qoK7cKWF2yvDpvK1rf1pDP/RXoV6udpRj010uaBrxb0mfJjjJ+XlQxEbEcOCZ/w+kWEas72qZOfgtMjog78ymlzyOb7uL9BdZ0Htm0GftJuh9oJPu4XbQzgLOBb0bE0/k5n6tdU5sflC2/Qnbvih+QvWl/tO4VbbAUeEjS/8trGQcslHQeQET8sKC67pJ0G/DrfHkCcGetdpbUBVN5YPUBDgRGAwJui4g7CqjlvM2tL/A/GACSdouI18va9o+IJ4uqKa+hO3AA2e/uiYhYW2Q9rSTtDPSLiGrNrFo1kvYgO0JcWHQtXU1HAwwi4t/rVUu5vNvtI/ni7yPiv2q1r6SO6PMum1kRMQSoe7iX2dx5ga7w7rqzpIuBfSNiTH43sA+RnQAtRDujDvaX9BqwKCJeKKImAEmfBL4P7AgMlDQMmBoRYwusaTYwluxv+BHgBUn3R8RmDzBqXNO3gO9GxKv58h7AP0dEYcOJS4M8r+fV6DpHt/OA1fmn6ndJ6lmzT/wRkdQX2Z2uRhZdR0k9oyppK6CuW4ETgQX5cneyQC2yplvIJsW7Kf9aBdxONnLjMwXW9QjZ1NvzS9r+WPDPan7+71nAv+ePF3aFmsra5hVUywXAgfnjnYC78/9bLwDHFPlzymv6LFlX6bJ8eTBwV632l9zwSuBQ4A+SlklaKGmRpCI/0l5SYVu97RUR1wProe3OYEWPcOkOHBQRx0fE8WT9vEH2O/1KgXWtjYjyk8LrC6lkg+75SI0TgZsLrqVVQ+vYfmjr7tppM8+vpQlAazfb6WRDyRuBI4BvFVRTqc8Do4DXASLiKeA9tdpZUl03ueOKLgBA0oeAw4DGsv763cimey5aVxzh0jci/lqy/ELe9rKkIvvqF0s6hSzIBgNfIBuiV6SpZNcc3BcRcyQNouAx68A1ZCcZf5kvn8GGe0nX29uRHyqTZcKvI5sifUl+Hqhob0XE29lpxbZzUzXrUuoK33BVRcSfACS9B+hRYCk7AruS/YxL++tfp2uMJOmKI1xmS7oZuCFfPj5v2wV4tbCq4Fzga8BbZBcl3QZ8o8B6iIgb2PBzIrLRXccXVxFExHckLQCOyZu+HhG3FVTOW5I+QDZs8SjgyyXr3lVMSRv5naT/TXau7FjgHLKRcDWR1KgbAEljyYZ17UN2RNgfWBIRhQwblNS/9c2nK5A0Eng2Iv6SH0X8L7KAeAy4ICJeLrA2kV3B+OG86RVg74j4fFE1QTZOPIodC/4OknqQXV35fkoOaCKiyKs+kdQfGBz5CUagIQoYUizpULJPE43AjyLi63n7/yA733NyvWsqq68b2e+vdHRgzYaBpxj0C8jG7d4ZEcMlHQWcFhF1nTNF0k8iYrKk39LOR7IoaMSGpHlkJ6NelvQR4DqyI9ZhZP3jhR7VSxoOnEJ2I5ungZsi4icF13QP8F7gRmBGRPyxyHoAJN0APE72s5pKdhn9koj4YoE1fRaYBPSKiP3ybq7LIuLoomrqqiRNjZKbN0lqAK6KiFNrsr8Eg35uRDTlgT88ItZLWhARh9S5jtcjYjdJR7S3PiJ+V896WpX+LCRdCrwYEf+WLz8aEcMKqGl/4OT86yVgBvDliNjkXe3rTdlkWCeSneTbjSzwC+u+ya9iHi5pYUQMlbQDcG9EfLDAmh4FmoGHImJ43rYosuHORdW0J3Ah2afEAO4jGxpb6NWx+XmMJyPi28ruxX098Gjr32K1JddHD7wqaVfg92TzbrxANpdLvS2D4gJ9Mxokdc9H2RxNdgTWqqj/D48D9wKfiIilAJK+VFAt7YqIvwD/kR/d/wvZ8L0i++lbT06/mvdF/4UajtqoUF1PMFboOrIsaD1/cSrZgcQxm9yiPsrnBbo1Ii6u1c6SCXpJ/SLiGbJLnN8EvkT2S92d7KNtvZWPttlIFHdl7K/JTgS9RPZzuhdA2SyIRY26+TTZ1M33SPpvsj9OFVTLO0g6iOxI/niysf0zgH8utCiYnl8A9H/ITqrvSvbmU6S6nmCsUO/W/vncN5RN5lcIbXpeoN/V8lxQMl03kuZFxIj88U35OOwi63ke+BmbCKwo9tLrDwK9gdsj4o28bX9g1yJPOuaja8aRdeF8FLgK+K+IuL2omvK6/kAW7tdHxJ+LrKUra+8EI/CLKDBkJP2QbJri6/Om8UBzRHx501vVtJ57NrM6IqIm8wKlFPTzS/oF2x4XWE/bG49tufxo9QRggk/mbbC5T4nQJeZQaszreLHgOlaTdRsJ2IUNFwM2AH+LiN0KrK0bcEJEzKjXPpPpumHjvsCu8O7VZboetkUR8QrZ9M7Ti6pB0vURcaKkRWz8f0pkR19DCyir6JvDvEM+LPZCYDL5zYyU3UfgkogootuUiOhyP6dW+QCR88k+JdZFSkf068hOugrYGWidV731j7Ku7+CSehU5Jt06T1LviHg+Hxv+Dl3p+ogi5Z8yPgZMioin87ZBZF2X/13Lk4ybqenAiHi8rE+8TdHXRUi6iA0jzNoGi9QqM5IJerNakfSdiPhKR211rulXwBdj45kif1DEBVPK7mx1bES8VNbeSHYeqO7dqJKmR8Sksj7xtrCrVV94pSQ93U5zRMSgWuwvxUnNzKrt2HbaPlb3KjY2tDXkoa2rq6jzUjuUhzy09dMXdSeuX0h6b0QcFRFHkd2m72/AHyl+qg8iYmA7XzUJeUirj96sqiR9jmyI4CBtPANqT7IhcUXqJmmPPOCR1Ivi/p7f3sp1tXQZ+Vj5/Arwb7PhCvDpdIGwz69/OJiNp7C4qhb7ctCbbdq1ZPP2fxuYUtK+ugucf/kB8KCk1mGDJwDfLKiWQyS93k67KG5iwYaS39EEYHpE3ATclF/BWyhld746kizoZ5F9QryPbEhx9ffnPnqzyqhsRtT8Ar3CKLsrWGtf890R8ViR9XQlkv4IDIuIFkmPk50o/n3ruoj4QMH1LQIOIbtZyyGS9gb+MyLa6ybsNB/Rm3VA2a0Ef0jZjKgUcCP1fNbKs4H3AYvIJg1rqXcd24CueAV4qTfzYZYtknYjv/dCrXbmoDfr2DeAD1I2I2pBtfyKbJ6be8k+7h8E/FNBtXRZEfFNSXex4Qrw1q6LbmR99UWbK+ndwM/JblX5N+APtdqZu27MOtBVZkTNa2mbDTKfNOxhX4G9bZM0ANgtImp2y1Mf0Zt1rKvMiAobZq0k738uqAzrLEmtN9lpnT65ZkHvI3qzDuSTra0hG0XSOiPqNUXMaV5yBThsfBV4IVeA29aR9FOy8yy/zpsmAMuiRndTc9CbmdVZPhLooNZzB/lEZ4sj4qBa7M9dN2abUDIDYlsTG2ZE9NGzdcZSoB/QOl9S37ytJhz0ZpvQlWdAtG2TNtxDuiewRNLD+fKhZPPm14SD3qwCkj4MDI6IX0raC+jZOlOj2Rb4fhE7dR+9WQfyy9WbgAMiYn9J+wA3RMSogkuzbVx+sVTbAXetptbwEb1Zxz5FNjPkPICI+LMkd+vYVpM0iexe1muA9Ww4/1OTGSwd9GYdezsiQlLrCIldii7ItnnnAx9ob3rnWvB89Gabkd8m72ZJ04B3S/oscCfZpetmW2sZG+6CV3PuozfrQD7T4HnAaLKP2LdFxB3FVmXbMknDgV8CDwFvtbZHxBdqsT933Zh1bB7wakScX3QhloxpwN1kM5Cur/XOfERv1oH8Ksb3kV3cUnoj56GFFWXbNEnz63kvXQe9WQck9W+vPSL+1F67WUckfQtYAfyWjbtuajK80kFvZlZnktq72C5qdYNwB72ZWeI8vNLMrE4k/UvJ4xPK1n2rVvt10JuZ1c9JJY+/WrZuTK126qA3M6sfbeJxe8tV46A3M6uf2MTj9parxidjzczqpORWkKW3gSRf7hERO9Rkvw56M7O0uevGzCxxDnozs8Q56G27IekLkpZIumYLtxsg6ZRa1WVWaw56256cAxwbEadu4XYDgC0OekkNW7qNWS046G27IOkystu03Srpa5KukPSwpPmSxuXPGSDpXknz8q/D8s0vAg6X9KikL0maKOknJa99s6Qj88d/k/QDSQuAD0k6Ld/Po5KmOfytCA562y5ExNnAn4GjgF2AuyOiOV/+Xn57wBfIjvhHABOA/8g3nwLcGxHDIuLiDna1C/BQRBwCrMpfZ1REDAPWAVv6acKs03zjEdsejQbGSvpyvtwD6Ef2RvATScPIQnn/rXjtdcBN+eOjgX8A5mR3JGRnsjcTs7py0Nv2SMDxEfHERo3SvwF/BQ4h+7S7ZhPbt7Dxp+EeJY/XRMS6kv38KiLK5zQxqyt33dj26Dbg3PzG36337wTYHXg+ItYDnwFa+9NXAz1Ltl8BDJPUTVJfoHkT+7kLGC/pPfl+em3qJiZmteSgt+3R14EdgIWSFufLAD8FTs9PpB7IhtsGLgTWSVog6UvA/cDTwGNk/fjz2ttJRDwG/Ctwu6SFwB1A79p8S2ab5ikQzMwS5yN6M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscf8ftqZkn8+kbKQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-30T14:14:56.086Z"
    },
    "cell_id": "00006-bd460b3a-46fe-43a7-b4c4-ce59c0f3bf03",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 91,
    "execution_start": 1612016768333,
    "output_cleared": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10, 25, 50, 70], \"min_samples_split\" : [2, 4, 10, 12, 16, 18, 25, 35], \"n_estimators\": [100, 400, 700, 1000, 1500]}\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "rf = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n",
    "clf = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1)\n",
    "clf.fit(X_train_norm, y_train)\n",
    "clf.bestparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00007-02b2241f-dd5c-422c-a1ad-fc9b4964590a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 65,
    "execution_start": 1612023726581,
    "source_hash": "a9bbc29a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC-Score: 0.940457416539421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_scores = random_forest.predict_proba(X_train_norm)\n",
    "y_scores = y_scores[:,1]\n",
    "\n",
    "r_a_score = roc_auc_score(y_train, y_scores)\n",
    "print(\"ROC-AUC-Score:\", r_a_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "00008-100f6b72-6767-4c63-b937-93fad04f46a9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 174,
    "execution_start": 1612023732147,
    "source_hash": "d7e6422f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(y_train, y_scores)\n",
    "def plot_precision_and_recall(precision, recall, threshold):\n",
    "    plt.plot(threshold, precision[:-1], \"r-\", label=\"precision\", linewidth=5)\n",
    "    plt.plot(threshold, recall[:-1], \"b\", label=\"recall\", linewidth=5)\n",
    "    plt.xlabel(\"threshold\", fontsize=19)\n",
    "    plt.legend(loc=\"upper right\", fontsize=19)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plot_precision_and_recall(precision, recall, threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-8761cf6d-2dbd-48ec-93fc-efcdebf2b0df",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "00010-75303f64-cd74-4e60-aca9-d92fdbb27eca",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1612025367423,
    "source_hash": "b3d7ed8a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 1000],  \n",
    "              'gamma': ['scale', 1, 0.1, 0.0001], 'kernel': ['poly', 'rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, verbose=1) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "00011-f70365b0-8745-45c9-9c0d-9367f4f9232f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1186868,
    "execution_start": 1612025369666,
    "source_hash": "4120ee57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVC(C=1)\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train_norm, y_train) \n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "00013-4f2e031a-26a4-432b-b352-12472c0b3788",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1612026812244,
    "source_hash": "9dedd157",
    "tags": []
   },
   "outputs": [],
   "source": [
    "svc_pred = grid.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "00014-b10b9f3d-be3e-4152-99ea-e642c688be42",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1612041621597,
    "source_hash": "60279ccd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268156424581006"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, svc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T13:59:17.868367Z",
     "start_time": "2021-01-30T13:59:17.856058Z"
    },
    "cell_id": "00002-b30a25cc-a956-4747-9558-6dff7cf902a1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1611989958749,
    "source_hash": "a5eb888b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T14:00:24.356908Z",
     "start_time": "2021-01-30T14:00:24.353036Z"
    },
    "cell_id": "00003-a394d79d-9ee0-4694-a65f-febac2dc5504",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1611995101277,
    "source_hash": "ccf0ff73",
    "tags": []
   },
   "outputs": [],
   "source": [
    "models1 = {\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "params1 = {\n",
    "    'ExtraTreesClassifier': {'n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': {'n_estimators': [16, 32] },\n",
    "    'AdaBoostClassifier':  {'n_estimators': [16, 32] },\n",
    "    'GradientBoostingClassifier': {'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-504395c2-f53c-4766-87a0-7a4de61224b1",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "models2 = {\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC(),\n",
    "}\n",
    "\n",
    "params2 = {\n",
    "    'ExtraTreesClassifier': {'n_estimators': [16, 32] },\n",
    "    'RandomForestClassifier': {'n_estimators': [16, 32] },\n",
    "    'AdaBoostClassifier':  {'n_estimators': [16, 32] },\n",
    "    'GradientBoostingClassifier': {'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100]},\n",
    "        {'kernel': ['rbf', 'poly', 'sigmoid', 'linear'], 'C':[0.1, 1, 10, 100], 'gamma': [1,0.1,0.01,0.001]},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T11:27:00.841630Z",
     "start_time": "2021-01-30T11:27:00.636220Z"
    },
    "cell_id": "00008-b5a603c8-2bd5-43b9-9ad8-d31dcc707978",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 255,
    "execution_start": 1612007250508,
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test_norm)\n",
    "\n",
    "clf.score(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T13:50:38.809632Z",
     "start_time": "2021-01-30T13:50:38.805836Z"
    },
    "cell_id": "00009-205f02fa-45c8-4e2d-b29c-dcad02dad41f",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "10.0 ** -np.arange(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T14:00:34.960826Z",
     "start_time": "2021-01-30T14:00:34.944269Z"
    },
    "cell_id": "00001-6006f514-39f9-4243-9f66-02c6ac82ff91",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 97,
    "execution_start": 1611990033981,
    "source_hash": "1cb720cd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/backend/resource_tracker.py:120: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some folders/sempahores might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n",
      "exception calling callback for <Future at 0x7fc790ab3590 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 359, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 792, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\", line 178, in submit\n",
      "    fn, *args, **kwargs)\n",
      "  File \"/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 1102, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
      "\n",
      "The exit codes of the workers are {EXIT(1)}\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/backend/resource_tracker.py:120: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some folders/sempahores might leak.\n",
      "  warnings.warn('resource_tracker: process died unexpectedly, '\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-55c3ef2e8eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhelper1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEstimatorSelectionHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhelper1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-5b3de598f71b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     18\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               return_train_score=True)\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_searches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \"\"\"\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0;32m--> 178\u001b[0;31m                 fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m                 raise ShutdownExecutorError(\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {EXIT(1)}"
     ]
    }
   ],
   "source": [
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(X_train_norm, y_train, scoring='f1', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T13:59:42.472026Z",
     "start_time": "2021-01-30T13:59:42.439506Z"
    },
    "cell_id": "00002-212c8998-2040-4b46-9f57-35e36a76bd59",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(helper1.score_summary(sort_by='max_score').head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T07:17:58.523966Z",
     "start_time": "2021-01-30T07:17:58.521477Z"
    },
    "cell_id": "00008-05e6b383-ba5a-4286-b054-61003bb52ab2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "440908b4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "'LogReg': LogisticRegression()\n",
    "'LinReg': LinearRegression()\n",
    "'KNeighborsClassifier': KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-ac3ffb39-2635-4fbe-8355-3e34ea40f67e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T21:53:52.097630Z",
     "start_time": "2021-01-30T21:53:51.955145Z"
    },
    "cell_id": "00011-784f885b-d87e-4b0e-9e29-810e9d76366f",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobiasschulz/opt/anaconda3/envs/ml_3_7/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T21:54:33.990818Z",
     "start_time": "2021-01-30T21:54:33.988027Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T21:54:56.226412Z",
     "start_time": "2021-01-30T21:54:56.222352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7597765363128491"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T21:53:03.322098Z",
     "start_time": "2021-01-30T21:52:57.969953Z"
    },
    "cell_id": "00012-1166e287-38e9-455d-bdab-db12c18fe7b4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 337,
    "execution_start": 1612014358491,
    "source_hash": "741c1b66",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(max_iter=50), n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'alpha': [0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06],\n",
       "                         'early_stopping': [True],\n",
       "                         'hidden_layer_sizes': [(10, 30, 10), (20,)],\n",
       "                         'momentum': [0.99, 0.5, 0.1, 0.01, 0.001],\n",
       "                         'random_state': [0], 'solver': ['sgd']})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_gs = MLPClassifier(max_iter=50)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd'],\n",
    "    'alpha': list(10.0 ** -np.arange(1, 7)), 'random_state': [0],\n",
    "    'momentum': [0.99, 0.5, 0.1, 0.01, 0.001], 'early_stopping': [True]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "mlp_clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=5)\n",
    "mlp_clf.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T21:53:23.560328Z",
     "start_time": "2021-01-30T21:53:23.555802Z"
    },
    "cell_id": "00019-73ba5083-fc14-44c1-9e32-d77d9fd688ed",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'alpha': 0.01,\n",
       " 'early_stopping': True,\n",
       " 'hidden_layer_sizes': (20,),\n",
       " 'momentum': 0.99,\n",
       " 'random_state': 0,\n",
       " 'solver': 'sgd'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T21:53:33.105482Z",
     "start_time": "2021-01-30T21:53:33.100595Z"
    },
    "cell_id": "00020-9fd49fb0-54c1-41b3-bd2c-594e9f57b168",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.770949720670391"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = mlp_clf.predict(X_test_norm)\n",
    "\n",
    "mlp_clf.score(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T11:19:18.830143Z",
     "start_time": "2021-01-30T11:16:35.550352Z"
    },
    "cell_id": "00012-bd537f71-6d18-4ac4-92da-cfcbfecf25b8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 34990,
    "execution_start": 1612014078635,
    "scrolled": false,
    "source_hash": "b1013a22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.41420798\n",
      "Iteration 28, loss = 0.41352678\n",
      "Iteration 29, loss = 0.41290442\n",
      "Iteration 30, loss = 0.41236020\n",
      "Iteration 31, loss = 0.41191421\n",
      "Iteration 32, loss = 0.41169502\n",
      "Iteration 33, loss = 0.41133468\n",
      "Iteration 34, loss = 0.41099500\n",
      "Iteration 35, loss = 0.41078443\n",
      "Iteration 36, loss = 0.41059346\n",
      "Iteration 37, loss = 0.41034743\n",
      "Iteration 38, loss = 0.41016852\n",
      "Iteration 39, loss = 0.40999217\n",
      "Iteration 40, loss = 0.40987374\n",
      "Iteration 41, loss = 0.40972533\n",
      "Iteration 42, loss = 0.40963890\n",
      "Iteration 43, loss = 0.40953258\n",
      "Iteration 44, loss = 0.40936160\n",
      "Iteration 45, loss = 0.40920815\n",
      "Iteration 46, loss = 0.40912359\n",
      "Iteration 47, loss = 0.40891048\n",
      "Iteration 48, loss = 0.40877274\n",
      "Iteration 49, loss = 0.40863469\n",
      "Iteration 50, loss = 0.40850314\n",
      "Iteration 51, loss = 0.40844405\n",
      "Iteration 52, loss = 0.40831000\n",
      "Iteration 53, loss = 0.40809418\n",
      "Iteration 54, loss = 0.40805703\n",
      "Iteration 55, loss = 0.40789685\n",
      "Iteration 56, loss = 0.40777843\n",
      "Iteration 57, loss = 0.40773617\n",
      "Iteration 58, loss = 0.40765441\n",
      "Iteration 59, loss = 0.40734714\n",
      "Iteration 60, loss = 0.40722810\n",
      "Iteration 61, loss = 0.40731651\n",
      "Iteration 62, loss = 0.40735609\n",
      "Iteration 63, loss = 0.40705611\n",
      "Iteration 64, loss = 0.40686461\n",
      "Iteration 65, loss = 0.40658625\n",
      "Iteration 66, loss = 0.40655840\n",
      "Iteration 67, loss = 0.40634327\n",
      "Iteration 68, loss = 0.40639197\n",
      "Iteration 69, loss = 0.40611444\n",
      "Iteration 70, loss = 0.40605642\n",
      "Iteration 71, loss = 0.40588233\n",
      "Iteration 72, loss = 0.40579491\n",
      "Iteration 73, loss = 0.40562268\n",
      "Iteration 74, loss = 0.40551729\n",
      "Iteration 75, loss = 0.40540174\n",
      "Iteration 76, loss = 0.40533982\n",
      "Iteration 77, loss = 0.40512861\n",
      "Iteration 78, loss = 0.40510965\n",
      "Iteration 79, loss = 0.40484282\n",
      "Iteration 80, loss = 0.40478634\n",
      "Iteration 81, loss = 0.40468553\n",
      "Iteration 82, loss = 0.40450501\n",
      "Iteration 83, loss = 0.40452853\n",
      "Iteration 84, loss = 0.40431373\n",
      "Iteration 85, loss = 0.40412978\n",
      "Iteration 86, loss = 0.40417521\n",
      "Iteration 87, loss = 0.40388893\n",
      "Iteration 88, loss = 0.40390006\n",
      "Iteration 89, loss = 0.40361192\n",
      "Iteration 90, loss = 0.40353255\n",
      "Iteration 91, loss = 0.40348599\n",
      "Iteration 92, loss = 0.40331294\n",
      "Iteration 93, loss = 0.40311831\n",
      "Iteration 94, loss = 0.40306952\n",
      "Iteration 95, loss = 0.40281864\n",
      "Iteration 96, loss = 0.40302265\n",
      "Iteration 97, loss = 0.40259151\n",
      "Iteration 98, loss = 0.40250342\n",
      "Iteration 99, loss = 0.40233853\n",
      "Iteration 100, loss = 0.40235451\n",
      "Iteration 101, loss = 0.40209145\n",
      "Iteration 102, loss = 0.40199168\n",
      "Iteration 103, loss = 0.40177305\n",
      "Iteration 104, loss = 0.40174353\n",
      "Iteration 105, loss = 0.40152465\n",
      "Iteration 106, loss = 0.40142222\n",
      "Iteration 107, loss = 0.40131221\n",
      "Iteration 108, loss = 0.40133138\n",
      "Iteration 109, loss = 0.40101792\n",
      "Iteration 110, loss = 0.40097575\n",
      "Iteration 111, loss = 0.40077692\n",
      "Iteration 112, loss = 0.40055444\n",
      "Iteration 113, loss = 0.40053510\n",
      "Iteration 114, loss = 0.40027996\n",
      "Iteration 115, loss = 0.40020192\n",
      "Iteration 116, loss = 0.40007923\n",
      "Iteration 117, loss = 0.39986789\n",
      "Iteration 118, loss = 0.39981067\n",
      "Iteration 119, loss = 0.39965036\n",
      "Iteration 120, loss = 0.39948051\n",
      "Iteration 121, loss = 0.39946303\n",
      "Iteration 122, loss = 0.39919636\n",
      "Iteration 123, loss = 0.39916664\n",
      "Iteration 124, loss = 0.39912801\n",
      "Iteration 125, loss = 0.39892007\n",
      "Iteration 126, loss = 0.39866191\n",
      "Iteration 127, loss = 0.39851836\n",
      "Iteration 128, loss = 0.39836920\n",
      "Iteration 129, loss = 0.39821300\n",
      "Iteration 130, loss = 0.39806474\n",
      "Iteration 131, loss = 0.39807198\n",
      "Iteration 132, loss = 0.39776130\n",
      "Iteration 133, loss = 0.39765272\n",
      "Iteration 134, loss = 0.39751504\n",
      "Iteration 135, loss = 0.39731429\n",
      "Iteration 136, loss = 0.39715037\n",
      "Iteration 137, loss = 0.39714971\n",
      "Iteration 138, loss = 0.39686192\n",
      "Iteration 139, loss = 0.39690699\n",
      "Iteration 140, loss = 0.39674777\n",
      "Iteration 141, loss = 0.39648565\n",
      "Iteration 142, loss = 0.39629397\n",
      "Iteration 143, loss = 0.39620442\n",
      "Iteration 144, loss = 0.39599110\n",
      "Iteration 145, loss = 0.39612421\n",
      "Iteration 146, loss = 0.39583763\n",
      "Iteration 147, loss = 0.39556858\n",
      "Iteration 148, loss = 0.39556715\n",
      "Iteration 149, loss = 0.39532407\n",
      "Iteration 150, loss = 0.39510916\n",
      "Iteration 151, loss = 0.39509200\n",
      "Iteration 152, loss = 0.39480222\n",
      "Iteration 153, loss = 0.39467426\n",
      "Iteration 154, loss = 0.39461496\n",
      "Iteration 155, loss = 0.39479387\n",
      "Iteration 156, loss = 0.39413297\n",
      "Iteration 157, loss = 0.39399333\n",
      "Iteration 158, loss = 0.39390673\n",
      "Iteration 159, loss = 0.39370574\n",
      "Iteration 160, loss = 0.39358935\n",
      "Iteration 161, loss = 0.39334892\n",
      "Iteration 162, loss = 0.39335816\n",
      "Iteration 163, loss = 0.39310039\n",
      "Iteration 164, loss = 0.39291349\n",
      "Iteration 165, loss = 0.39288109\n",
      "Iteration 166, loss = 0.39266014\n",
      "Iteration 167, loss = 0.39251133\n",
      "Iteration 168, loss = 0.39227840\n",
      "Iteration 169, loss = 0.39224802\n",
      "Iteration 170, loss = 0.39193075\n",
      "Iteration 171, loss = 0.39172977\n",
      "Iteration 172, loss = 0.39170812\n",
      "Iteration 173, loss = 0.39159032\n",
      "Iteration 174, loss = 0.39129402\n",
      "Iteration 175, loss = 0.39105600\n",
      "Iteration 176, loss = 0.39135475\n",
      "Iteration 177, loss = 0.39093484\n",
      "Iteration 178, loss = 0.39071448\n",
      "Iteration 179, loss = 0.39058892\n",
      "Iteration 180, loss = 0.39030546\n",
      "Iteration 181, loss = 0.39031989\n",
      "Iteration 182, loss = 0.39000024\n",
      "Iteration 183, loss = 0.38995182\n",
      "Iteration 184, loss = 0.38971307\n",
      "Iteration 185, loss = 0.38963368\n",
      "Iteration 186, loss = 0.38936247\n",
      "Iteration 187, loss = 0.38935814\n",
      "Iteration 188, loss = 0.38900175\n",
      "Iteration 189, loss = 0.38882879\n",
      "Iteration 190, loss = 0.38880803\n",
      "Iteration 191, loss = 0.38841697\n",
      "Iteration 192, loss = 0.38839634\n",
      "Iteration 193, loss = 0.38818780\n",
      "Iteration 194, loss = 0.38815772\n",
      "Iteration 195, loss = 0.38802441\n",
      "Iteration 196, loss = 0.38770687\n",
      "Iteration 197, loss = 0.38738552\n",
      "Iteration 198, loss = 0.38736928\n",
      "Iteration 199, loss = 0.38716175\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "Iteration 200, loss = 0.38702878\n",
      "Iteration 1, loss = 0.75832456\n",
      "Iteration 2, loss = 0.71171039\n",
      "Iteration 3, loss = 0.66908978\n",
      "Iteration 4, loss = 0.63545083\n",
      "Iteration 5, loss = 0.60680628\n",
      "Iteration 6, loss = 0.58225380\n",
      "Iteration 7, loss = 0.56040464\n",
      "Iteration 8, loss = 0.54365459\n",
      "Iteration 9, loss = 0.52775228\n",
      "Iteration 10, loss = 0.51479965\n",
      "Iteration 11, loss = 0.50303278\n",
      "Iteration 12, loss = 0.49322982\n",
      "Iteration 13, loss = 0.48382353\n",
      "Iteration 14, loss = 0.47646565\n",
      "Iteration 15, loss = 0.46965282\n",
      "Iteration 16, loss = 0.46390666\n",
      "Iteration 17, loss = 0.45887594\n",
      "Iteration 18, loss = 0.45518417\n",
      "Iteration 19, loss = 0.45147907\n",
      "Iteration 20, loss = 0.44831786\n",
      "Iteration 21, loss = 0.44584141\n",
      "Iteration 22, loss = 0.44361769\n",
      "Iteration 23, loss = 0.44229591\n",
      "Iteration 24, loss = 0.44069308\n",
      "Iteration 25, loss = 0.43972276\n",
      "Iteration 26, loss = 0.43856770\n",
      "Iteration 27, loss = 0.43787131\n",
      "Iteration 28, loss = 0.43722117\n",
      "Iteration 29, loss = 0.43645116\n",
      "Iteration 30, loss = 0.43609639\n",
      "Iteration 31, loss = 0.43551459\n",
      "Iteration 32, loss = 0.43535283\n",
      "Iteration 33, loss = 0.43495016\n",
      "Iteration 34, loss = 0.43457925\n",
      "Iteration 35, loss = 0.43431085\n",
      "Iteration 36, loss = 0.43416272\n",
      "Iteration 37, loss = 0.43385617\n",
      "Iteration 38, loss = 0.43367446\n",
      "Iteration 39, loss = 0.43348782\n",
      "Iteration 40, loss = 0.43342159\n",
      "Iteration 41, loss = 0.43312504\n",
      "Iteration 42, loss = 0.43304791\n",
      "Iteration 43, loss = 0.43291141\n",
      "Iteration 44, loss = 0.43278707\n",
      "Iteration 45, loss = 0.43255913\n",
      "Iteration 46, loss = 0.43244030\n",
      "Iteration 47, loss = 0.43227622\n",
      "Iteration 48, loss = 0.43218995\n",
      "Iteration 49, loss = 0.43208251\n",
      "Iteration 50, loss = 0.43196295\n",
      "Iteration 51, loss = 0.43182412\n",
      "Iteration 52, loss = 0.43164683\n",
      "Iteration 53, loss = 0.43154447\n",
      "Iteration 54, loss = 0.43144968\n",
      "Iteration 55, loss = 0.43128637\n",
      "Iteration 56, loss = 0.43119653\n",
      "Iteration 57, loss = 0.43105918\n",
      "Iteration 58, loss = 0.43095178\n",
      "Iteration 59, loss = 0.43080071\n",
      "Iteration 60, loss = 0.43073039\n",
      "Iteration 61, loss = 0.43068113\n",
      "Iteration 62, loss = 0.43050218\n",
      "Iteration 63, loss = 0.43032608\n",
      "Iteration 64, loss = 0.43028896\n",
      "Iteration 65, loss = 0.43007265\n",
      "Iteration 66, loss = 0.43004319\n",
      "Iteration 67, loss = 0.42980009\n",
      "Iteration 68, loss = 0.42986655\n",
      "Iteration 69, loss = 0.42971458\n",
      "Iteration 70, loss = 0.42953243\n",
      "Iteration 71, loss = 0.42937826\n",
      "Iteration 72, loss = 0.42919914\n",
      "Iteration 73, loss = 0.42921312\n",
      "Iteration 74, loss = 0.42908183\n",
      "Iteration 75, loss = 0.42889643\n",
      "Iteration 76, loss = 0.42881326\n",
      "Iteration 77, loss = 0.42864137\n",
      "Iteration 78, loss = 0.42853673\n",
      "Iteration 79, loss = 0.42835868\n",
      "Iteration 80, loss = 0.42825301\n",
      "Iteration 81, loss = 0.42835717\n",
      "Iteration 82, loss = 0.42801414\n",
      "Iteration 83, loss = 0.42818806\n",
      "Iteration 84, loss = 0.42783339\n",
      "Iteration 85, loss = 0.42761297\n",
      "Iteration 86, loss = 0.42751908\n",
      "Iteration 87, loss = 0.42744036\n",
      "Iteration 88, loss = 0.42735742\n",
      "Iteration 89, loss = 0.42716826\n",
      "Iteration 90, loss = 0.42706531\n",
      "Iteration 91, loss = 0.42704405\n",
      "Iteration 92, loss = 0.42680241\n",
      "Iteration 93, loss = 0.42663561\n",
      "Iteration 94, loss = 0.42687294\n",
      "Iteration 95, loss = 0.42650003\n",
      "Iteration 96, loss = 0.42638021\n",
      "Iteration 97, loss = 0.42625089\n",
      "Iteration 98, loss = 0.42628804\n",
      "Iteration 99, loss = 0.42598435\n",
      "Iteration 100, loss = 0.42584507\n",
      "Iteration 101, loss = 0.42579035\n",
      "Iteration 102, loss = 0.42563571\n",
      "Iteration 103, loss = 0.42553876\n",
      "Iteration 104, loss = 0.42538356\n",
      "Iteration 105, loss = 0.42541670\n",
      "Iteration 106, loss = 0.42510380\n",
      "Iteration 107, loss = 0.42494520\n",
      "Iteration 108, loss = 0.42486613\n",
      "Iteration 109, loss = 0.42474291\n",
      "Iteration 110, loss = 0.42463552\n",
      "Iteration 111, loss = 0.42454258\n",
      "Iteration 112, loss = 0.42428126\n",
      "Iteration 113, loss = 0.42429561\n",
      "Iteration 114, loss = 0.42405354\n",
      "Iteration 115, loss = 0.42397731\n",
      "Iteration 116, loss = 0.42400499\n",
      "Iteration 117, loss = 0.42372603\n",
      "Iteration 118, loss = 0.42362567\n",
      "Iteration 119, loss = 0.42352972\n",
      "Iteration 120, loss = 0.42329969\n",
      "Iteration 121, loss = 0.42332145\n",
      "Iteration 122, loss = 0.42311123\n",
      "Iteration 123, loss = 0.42295521\n",
      "Iteration 124, loss = 0.42293622\n",
      "Iteration 125, loss = 0.42268475\n",
      "Iteration 126, loss = 0.42260736\n",
      "Iteration 127, loss = 0.42239074\n",
      "Iteration 128, loss = 0.42218532\n",
      "Iteration 129, loss = 0.42227088\n",
      "Iteration 130, loss = 0.42204903\n",
      "Iteration 131, loss = 0.42192339\n",
      "Iteration 132, loss = 0.42171876\n",
      "Iteration 133, loss = 0.42168535\n",
      "Iteration 134, loss = 0.42148389\n",
      "Iteration 135, loss = 0.42137394\n",
      "Iteration 136, loss = 0.42116455\n",
      "Iteration 137, loss = 0.42112799\n",
      "Iteration 138, loss = 0.42088920\n",
      "Iteration 139, loss = 0.42118739\n",
      "Iteration 140, loss = 0.42071229\n",
      "Iteration 141, loss = 0.42074136\n",
      "Iteration 142, loss = 0.42037979\n",
      "Iteration 143, loss = 0.42024110\n",
      "Iteration 144, loss = 0.42013896\n",
      "Iteration 145, loss = 0.42003779\n",
      "Iteration 146, loss = 0.41997541\n",
      "Iteration 147, loss = 0.41976172\n",
      "Iteration 148, loss = 0.41976130\n",
      "Iteration 149, loss = 0.41945519\n",
      "Iteration 150, loss = 0.41921402\n",
      "Iteration 151, loss = 0.41923311\n",
      "Iteration 152, loss = 0.41902584\n",
      "Iteration 153, loss = 0.41879022\n",
      "Iteration 154, loss = 0.41890437\n",
      "Iteration 155, loss = 0.41906926\n",
      "Iteration 156, loss = 0.41849188\n",
      "Iteration 157, loss = 0.41827165\n",
      "Iteration 158, loss = 0.41823477\n",
      "Iteration 159, loss = 0.41828071\n",
      "Iteration 160, loss = 0.41783146\n",
      "Iteration 161, loss = 0.41772492\n",
      "Iteration 162, loss = 0.41772731\n",
      "Iteration 163, loss = 0.41751204\n",
      "Iteration 164, loss = 0.41724267\n",
      "Iteration 165, loss = 0.41717906\n",
      "Iteration 166, loss = 0.41706908\n",
      "Iteration 167, loss = 0.41696108\n",
      "Iteration 168, loss = 0.41668694\n",
      "Iteration 169, loss = 0.41655511\n",
      "Iteration 170, loss = 0.41645120\n",
      "Iteration 171, loss = 0.41639993\n",
      "Iteration 172, loss = 0.41612656\n",
      "Iteration 173, loss = 0.41610258\n",
      "Iteration 174, loss = 0.41588099\n",
      "Iteration 175, loss = 0.41579163\n",
      "Iteration 176, loss = 0.41573125\n",
      "Iteration 177, loss = 0.41543041\n",
      "Iteration 178, loss = 0.41536297\n",
      "Iteration 179, loss = 0.41509700\n",
      "Iteration 180, loss = 0.41501808\n",
      "Iteration 181, loss = 0.41491652\n",
      "Iteration 182, loss = 0.41455405\n",
      "Iteration 183, loss = 0.41444035\n",
      "Iteration 184, loss = 0.41433950\n",
      "Iteration 185, loss = 0.41421429\n",
      "Iteration 186, loss = 0.41399110\n",
      "Iteration 187, loss = 0.41418659\n",
      "Iteration 188, loss = 0.41380807\n",
      "Iteration 189, loss = 0.41361941\n",
      "Iteration 190, loss = 0.41345939\n",
      "Iteration 191, loss = 0.41320752\n",
      "Iteration 192, loss = 0.41316211\n",
      "Iteration 193, loss = 0.41294116\n",
      "Iteration 194, loss = 0.41283627\n",
      "Iteration 195, loss = 0.41281803\n",
      "Iteration 196, loss = 0.41252444\n",
      "Iteration 197, loss = 0.41227496\n",
      "Iteration 198, loss = 0.41215980\n",
      "Iteration 199, loss = 0.41202066\n",
      "Iteration 200, loss = 0.41187958\n",
      "Iteration 1, loss = 0.75925580\n",
      "Iteration 2, loss = 0.71274133\n",
      "Iteration 3, loss = 0.67284115\n",
      "Iteration 4, loss = 0.63924087\n",
      "Iteration 5, loss = 0.61040600\n",
      "Iteration 6, loss = 0.58464224\n",
      "Iteration 7, loss = 0.56405912\n",
      "Iteration 8, loss = 0.54508177\n",
      "Iteration 9, loss = 0.52817072\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "Iteration 10, loss = 0.51336129\n",
      "Iteration 11, loss = 0.50062726\n",
      "Iteration 12, loss = 0.48909053\n",
      "Iteration 13, loss = 0.47921894\n",
      "Iteration 14, loss = 0.47016732\n",
      "Iteration 15, loss = 0.46260794\n",
      "Iteration 16, loss = 0.45634034\n",
      "Iteration 17, loss = 0.45074090\n",
      "Iteration 18, loss = 0.44650673\n",
      "Iteration 19, loss = 0.44231222\n",
      "Iteration 20, loss = 0.43847968\n",
      "Iteration 21, loss = 0.43584833\n",
      "Iteration 22, loss = 0.43333389\n",
      "Iteration 23, loss = 0.43114110\n",
      "Iteration 24, loss = 0.42953874\n",
      "Iteration 25, loss = 0.42815390\n",
      "Iteration 26, loss = 0.42688468\n",
      "Iteration 27, loss = 0.42572668\n",
      "Iteration 28, loss = 0.42504230\n",
      "Iteration 29, loss = 0.42410608\n",
      "Iteration 30, loss = 0.42355713\n",
      "Iteration 31, loss = 0.42308607\n",
      "Iteration 32, loss = 0.42256403\n",
      "Iteration 33, loss = 0.42241425\n",
      "Iteration 34, loss = 0.42177924\n",
      "Iteration 35, loss = 0.42156506\n",
      "Iteration 36, loss = 0.42114533\n",
      "Iteration 37, loss = 0.42099101\n",
      "Iteration 38, loss = 0.42066656\n",
      "Iteration 39, loss = 0.42032083\n",
      "Iteration 40, loss = 0.42022289\n",
      "Iteration 41, loss = 0.41994678\n",
      "Iteration 42, loss = 0.41979640\n",
      "Iteration 43, loss = 0.41946204\n",
      "Iteration 44, loss = 0.41949628\n",
      "Iteration 45, loss = 0.41914328\n",
      "Iteration 46, loss = 0.41892023\n",
      "Iteration 47, loss = 0.41871969\n",
      "Iteration 48, loss = 0.41864402\n",
      "Iteration 49, loss = 0.41841531\n",
      "Iteration 50, loss = 0.41825405\n",
      "Iteration 51, loss = 0.41812041\n",
      "Iteration 52, loss = 0.41801237\n",
      "Iteration 53, loss = 0.41775094\n",
      "Iteration 54, loss = 0.41756304\n",
      "Iteration 55, loss = 0.41741925\n",
      "Iteration 56, loss = 0.41736088\n",
      "Iteration 57, loss = 0.41725878\n",
      "Iteration 58, loss = 0.41704912\n",
      "Iteration 59, loss = 0.41682713\n",
      "Iteration 60, loss = 0.41672103\n",
      "Iteration 61, loss = 0.41656511\n",
      "Iteration 62, loss = 0.41643321\n",
      "Iteration 63, loss = 0.41626486\n",
      "Iteration 64, loss = 0.41618180\n",
      "Iteration 65, loss = 0.41597012\n",
      "Iteration 66, loss = 0.41595250\n",
      "Iteration 67, loss = 0.41587818\n",
      "Iteration 68, loss = 0.41562745\n",
      "Iteration 69, loss = 0.41540926\n",
      "Iteration 70, loss = 0.41543148\n",
      "Iteration 71, loss = 0.41515984\n",
      "Iteration 72, loss = 0.41504211\n",
      "Iteration 73, loss = 0.41484086\n",
      "Iteration 74, loss = 0.41474301\n",
      "Iteration 75, loss = 0.41455225\n",
      "Iteration 76, loss = 0.41459528\n",
      "Iteration 77, loss = 0.41422415\n",
      "Iteration 78, loss = 0.41410077\n",
      "Iteration 79, loss = 0.41397740\n",
      "Iteration 80, loss = 0.41392502\n",
      "Iteration 81, loss = 0.41376251\n",
      "Iteration 82, loss = 0.41363789\n",
      "Iteration 83, loss = 0.41345589\n",
      "Iteration 84, loss = 0.41331969\n",
      "Iteration 85, loss = 0.41332718\n",
      "Iteration 86, loss = 0.41316897\n",
      "Iteration 87, loss = 0.41309114\n",
      "Iteration 88, loss = 0.41275448\n",
      "Iteration 89, loss = 0.41263294\n",
      "Iteration 90, loss = 0.41261538\n",
      "Iteration 91, loss = 0.41233817\n",
      "Iteration 92, loss = 0.41254134\n",
      "Iteration 93, loss = 0.41211903\n",
      "Iteration 94, loss = 0.41239059\n",
      "Iteration 95, loss = 0.41180218\n",
      "Iteration 96, loss = 0.41160738\n",
      "Iteration 97, loss = 0.41148594\n",
      "Iteration 98, loss = 0.41128848\n",
      "Iteration 99, loss = 0.41119934\n",
      "Iteration 100, loss = 0.41101113\n",
      "Iteration 101, loss = 0.41120389\n",
      "Iteration 102, loss = 0.41080213\n",
      "Iteration 103, loss = 0.41062142\n",
      "Iteration 104, loss = 0.41060648\n",
      "Iteration 105, loss = 0.41032792\n",
      "Iteration 106, loss = 0.41031351\n",
      "Iteration 107, loss = 0.41009344\n",
      "Iteration 108, loss = 0.40992550\n",
      "Iteration 109, loss = 0.40977983\n",
      "Iteration 110, loss = 0.40958057\n",
      "Iteration 111, loss = 0.40948071\n",
      "Iteration 112, loss = 0.40940772\n",
      "Iteration 113, loss = 0.40913886\n",
      "Iteration 114, loss = 0.40906841\n",
      "Iteration 115, loss = 0.40886924\n",
      "Iteration 116, loss = 0.40862454\n",
      "Iteration 117, loss = 0.40849465\n",
      "Iteration 118, loss = 0.40838730\n",
      "Iteration 119, loss = 0.40839855\n",
      "Iteration 120, loss = 0.40823567\n",
      "Iteration 121, loss = 0.40798647\n",
      "Iteration 122, loss = 0.40783871\n",
      "Iteration 123, loss = 0.40759267\n",
      "Iteration 124, loss = 0.40757465\n",
      "Iteration 125, loss = 0.40744161\n",
      "Iteration 126, loss = 0.40716898\n",
      "Iteration 127, loss = 0.40696921\n",
      "Iteration 128, loss = 0.40687113\n",
      "Iteration 129, loss = 0.40677540\n",
      "Iteration 130, loss = 0.40659737\n",
      "Iteration 131, loss = 0.40636099\n",
      "Iteration 132, loss = 0.40627231\n",
      "Iteration 133, loss = 0.40610151\n",
      "Iteration 134, loss = 0.40594270\n",
      "Iteration 135, loss = 0.40566150\n",
      "Iteration 136, loss = 0.40590785\n",
      "Iteration 137, loss = 0.40534965\n",
      "Iteration 138, loss = 0.40523999\n",
      "Iteration 139, loss = 0.40523534\n",
      "Iteration 140, loss = 0.40492602\n",
      "Iteration 141, loss = 0.40477904\n",
      "Iteration 142, loss = 0.40456934\n",
      "Iteration 143, loss = 0.40442457\n",
      "Iteration 144, loss = 0.40436259\n",
      "Iteration 145, loss = 0.40421737\n",
      "Iteration 146, loss = 0.40398994\n",
      "Iteration 147, loss = 0.40383132\n",
      "Iteration 148, loss = 0.40373285\n",
      "Iteration 149, loss = 0.40338958\n",
      "Iteration 150, loss = 0.40321517\n",
      "Iteration 151, loss = 0.40308185\n",
      "Iteration 152, loss = 0.40296181\n",
      "Iteration 153, loss = 0.40330520\n",
      "Iteration 154, loss = 0.40271075\n",
      "Iteration 155, loss = 0.40226210\n",
      "Iteration 156, loss = 0.40230115\n",
      "Iteration 157, loss = 0.40207715\n",
      "Iteration 158, loss = 0.40187453\n",
      "Iteration 159, loss = 0.40170969\n",
      "Iteration 160, loss = 0.40162651\n",
      "Iteration 161, loss = 0.40141410\n",
      "Iteration 162, loss = 0.40128643\n",
      "Iteration 163, loss = 0.40102697\n",
      "Iteration 164, loss = 0.40099237\n",
      "Iteration 165, loss = 0.40074496\n",
      "Iteration 166, loss = 0.40053050\n",
      "Iteration 167, loss = 0.40022328\n",
      "Iteration 168, loss = 0.40011570\n",
      "Iteration 169, loss = 0.39992013\n",
      "Iteration 170, loss = 0.39989971\n",
      "Iteration 171, loss = 0.39959231\n",
      "Iteration 172, loss = 0.39959776\n",
      "Iteration 173, loss = 0.39937254\n",
      "Iteration 174, loss = 0.39916508\n",
      "Iteration 175, loss = 0.39891643\n",
      "Iteration 176, loss = 0.39876338\n",
      "Iteration 177, loss = 0.39845717\n",
      "Iteration 178, loss = 0.39852260\n",
      "Iteration 179, loss = 0.39816377\n",
      "Iteration 180, loss = 0.39793326\n",
      "Iteration 181, loss = 0.39770335\n",
      "Iteration 182, loss = 0.39757392\n",
      "Iteration 183, loss = 0.39727938\n",
      "Iteration 184, loss = 0.39717359\n",
      "Iteration 185, loss = 0.39721291\n",
      "Iteration 186, loss = 0.39690293\n",
      "Iteration 187, loss = 0.39672700\n",
      "Iteration 188, loss = 0.39650343\n",
      "Iteration 189, loss = 0.39633308\n",
      "Iteration 190, loss = 0.39604221\n",
      "Iteration 191, loss = 0.39592522\n",
      "Iteration 192, loss = 0.39573477\n",
      "Iteration 193, loss = 0.39541271\n",
      "Iteration 194, loss = 0.39546959\n",
      "Iteration 195, loss = 0.39526025\n",
      "Iteration 196, loss = 0.39495133\n",
      "Iteration 197, loss = 0.39502069\n",
      "Iteration 198, loss = 0.39462146\n",
      "Iteration 199, loss = 0.39444036\n",
      "Iteration 200, loss = 0.39405456\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "Iteration 1, loss = 0.76162014\n",
      "Iteration 2, loss = 0.71395006\n",
      "Iteration 3, loss = 0.67510773\n",
      "Iteration 4, loss = 0.64121698\n",
      "Iteration 5, loss = 0.61162532\n",
      "Iteration 6, loss = 0.58647122\n",
      "Iteration 7, loss = 0.56515843\n",
      "Iteration 8, loss = 0.54568044\n",
      "Iteration 9, loss = 0.52848800\n",
      "Iteration 10, loss = 0.51329764\n",
      "Iteration 11, loss = 0.50043738\n",
      "Iteration 12, loss = 0.48863707\n",
      "Iteration 13, loss = 0.47855389\n",
      "Iteration 14, loss = 0.46917606\n",
      "Iteration 15, loss = 0.46158790\n",
      "Iteration 16, loss = 0.45486821\n",
      "Iteration 17, loss = 0.44929371\n",
      "Iteration 18, loss = 0.44473472\n",
      "Iteration 19, loss = 0.44000009\n",
      "Iteration 20, loss = 0.43660628\n",
      "Iteration 21, loss = 0.43344395\n",
      "Iteration 22, loss = 0.43085293\n",
      "Iteration 23, loss = 0.42841577\n",
      "Iteration 24, loss = 0.42659647\n",
      "Iteration 25, loss = 0.42514503\n",
      "Iteration 26, loss = 0.42367574\n",
      "Iteration 27, loss = 0.42251075\n",
      "Iteration 28, loss = 0.42168396\n",
      "Iteration 29, loss = 0.42080892\n",
      "Iteration 30, loss = 0.42002364\n",
      "Iteration 31, loss = 0.41961428\n",
      "Iteration 32, loss = 0.41913147\n",
      "Iteration 33, loss = 0.41887045\n",
      "Iteration 34, loss = 0.41824601\n",
      "Iteration 35, loss = 0.41784690\n",
      "Iteration 36, loss = 0.41772247\n",
      "Iteration 37, loss = 0.41740640\n",
      "Iteration 38, loss = 0.41705388\n",
      "Iteration 39, loss = 0.41684399\n",
      "Iteration 40, loss = 0.41677747\n",
      "Iteration 41, loss = 0.41648069\n",
      "Iteration 42, loss = 0.41634041\n",
      "Iteration 43, loss = 0.41613864\n",
      "Iteration 44, loss = 0.41607032\n",
      "Iteration 45, loss = 0.41577224\n",
      "Iteration 46, loss = 0.41562564\n",
      "Iteration 47, loss = 0.41544361\n",
      "Iteration 48, loss = 0.41534689\n",
      "Iteration 49, loss = 0.41520264\n",
      "Iteration 50, loss = 0.41501851\n",
      "Iteration 51, loss = 0.41490496\n",
      "Iteration 52, loss = 0.41483717\n",
      "Iteration 53, loss = 0.41463435\n",
      "Iteration 54, loss = 0.41448395\n",
      "Iteration 55, loss = 0.41435733\n",
      "Iteration 56, loss = 0.41422265\n",
      "Iteration 57, loss = 0.41415416\n",
      "Iteration 58, loss = 0.41409455\n",
      "Iteration 59, loss = 0.41385033\n",
      "Iteration 60, loss = 0.41369608\n",
      "Iteration 61, loss = 0.41364965\n",
      "Iteration 62, loss = 0.41348600\n",
      "Iteration 63, loss = 0.41344461\n",
      "Iteration 64, loss = 0.41339266\n",
      "Iteration 65, loss = 0.41318384\n",
      "Iteration 66, loss = 0.41306960\n",
      "Iteration 67, loss = 0.41291770\n",
      "Iteration 68, loss = 0.41274353\n",
      "Iteration 69, loss = 0.41262646\n",
      "Iteration 70, loss = 0.41260336\n",
      "Iteration 71, loss = 0.41241218\n",
      "Iteration 72, loss = 0.41228095\n",
      "Iteration 73, loss = 0.41206310\n",
      "Iteration 74, loss = 0.41204438\n",
      "Iteration 75, loss = 0.41187849\n",
      "Iteration 76, loss = 0.41178018\n",
      "Iteration 77, loss = 0.41165065\n",
      "Iteration 78, loss = 0.41148491\n",
      "Iteration 79, loss = 0.41132729\n",
      "Iteration 80, loss = 0.41124716\n",
      "Iteration 81, loss = 0.41110591\n",
      "Iteration 82, loss = 0.41097227\n",
      "Iteration 83, loss = 0.41082922\n",
      "Iteration 84, loss = 0.41074306\n",
      "Iteration 85, loss = 0.41073770\n",
      "Iteration 86, loss = 0.41043923\n",
      "Iteration 87, loss = 0.41053682\n",
      "Iteration 88, loss = 0.41031485\n",
      "Iteration 89, loss = 0.41018276\n",
      "Iteration 90, loss = 0.41013977\n",
      "Iteration 91, loss = 0.40986338\n",
      "Iteration 92, loss = 0.40999788\n",
      "Iteration 93, loss = 0.40968275\n",
      "Iteration 94, loss = 0.40962614\n",
      "Iteration 95, loss = 0.40935542\n",
      "Iteration 96, loss = 0.40924826\n",
      "Iteration 97, loss = 0.40924337\n",
      "Iteration 98, loss = 0.40899168\n",
      "Iteration 99, loss = 0.40893600\n",
      "Iteration 100, loss = 0.40864166\n",
      "Iteration 101, loss = 0.40885910\n",
      "Iteration 102, loss = 0.40859987\n",
      "Iteration 103, loss = 0.40836482\n",
      "Iteration 104, loss = 0.40834533\n",
      "Iteration 105, loss = 0.40805694\n",
      "Iteration 106, loss = 0.40798833\n",
      "Iteration 107, loss = 0.40789748\n",
      "Iteration 108, loss = 0.40785903\n",
      "Iteration 109, loss = 0.40772875\n",
      "Iteration 110, loss = 0.40751156\n",
      "Iteration 111, loss = 0.40726331\n",
      "Iteration 112, loss = 0.40721151\n",
      "Iteration 113, loss = 0.40705374\n",
      "Iteration 114, loss = 0.40697341\n",
      "Iteration 115, loss = 0.40682594\n",
      "Iteration 116, loss = 0.40661627\n",
      "Iteration 117, loss = 0.40649390\n",
      "Iteration 118, loss = 0.40645542\n",
      "Iteration 119, loss = 0.40641639\n",
      "Iteration 120, loss = 0.40618601\n",
      "Iteration 121, loss = 0.40608514\n",
      "Iteration 122, loss = 0.40592832\n",
      "Iteration 123, loss = 0.40567719\n",
      "Iteration 124, loss = 0.40563873\n",
      "Iteration 125, loss = 0.40553267\n",
      "Iteration 126, loss = 0.40535461\n",
      "Iteration 127, loss = 0.40523251\n",
      "Iteration 128, loss = 0.40503912\n",
      "Iteration 129, loss = 0.40492429\n",
      "Iteration 130, loss = 0.40485407\n",
      "Iteration 131, loss = 0.40457422\n",
      "Iteration 132, loss = 0.40453176\n",
      "Iteration 133, loss = 0.40441106\n",
      "Iteration 134, loss = 0.40423741\n",
      "Iteration 135, loss = 0.40404837\n",
      "Iteration 136, loss = 0.40398508\n",
      "Iteration 137, loss = 0.40407400\n",
      "Iteration 138, loss = 0.40377217\n",
      "Iteration 139, loss = 0.40363388\n",
      "Iteration 140, loss = 0.40343406\n",
      "Iteration 141, loss = 0.40330334\n",
      "Iteration 142, loss = 0.40304042\n",
      "Iteration 143, loss = 0.40284689\n",
      "Iteration 144, loss = 0.40285986\n",
      "Iteration 145, loss = 0.40274835\n",
      "Iteration 146, loss = 0.40266281\n",
      "Iteration 147, loss = 0.40233181\n",
      "Iteration 148, loss = 0.40228323\n",
      "Iteration 149, loss = 0.40201160\n",
      "Iteration 150, loss = 0.40186503\n",
      "Iteration 151, loss = 0.40171049\n",
      "Iteration 152, loss = 0.40175858\n",
      "Iteration 153, loss = 0.40185728\n",
      "Iteration 154, loss = 0.40129325\n",
      "Iteration 155, loss = 0.40110511\n",
      "Iteration 156, loss = 0.40104225\n",
      "Iteration 157, loss = 0.40080889\n",
      "Iteration 158, loss = 0.40066116\n",
      "Iteration 159, loss = 0.40049427\n",
      "Iteration 160, loss = 0.40042652\n",
      "Iteration 161, loss = 0.40029959\n",
      "Iteration 162, loss = 0.40017089\n",
      "Iteration 163, loss = 0.39996527\n",
      "Iteration 164, loss = 0.39979336\n",
      "Iteration 165, loss = 0.39955392\n",
      "Iteration 166, loss = 0.39946992\n",
      "Iteration 167, loss = 0.39922656\n",
      "Iteration 168, loss = 0.39924487\n",
      "Iteration 169, loss = 0.39899522\n",
      "Iteration 170, loss = 0.39889903\n",
      "Iteration 171, loss = 0.39859018\n",
      "Iteration 172, loss = 0.39850296\n",
      "Iteration 173, loss = 0.39852792\n",
      "Iteration 174, loss = 0.39821081\n",
      "Iteration 175, loss = 0.39813231\n",
      "Iteration 176, loss = 0.39785049\n",
      "Iteration 177, loss = 0.39769413\n",
      "Iteration 178, loss = 0.39756950\n",
      "Iteration 179, loss = 0.39740728\n",
      "Iteration 180, loss = 0.39712439\n",
      "Iteration 181, loss = 0.39696699\n",
      "Iteration 182, loss = 0.39681519\n",
      "Iteration 183, loss = 0.39657970\n",
      "Iteration 184, loss = 0.39642274\n",
      "Iteration 185, loss = 0.39636589\n",
      "Iteration 186, loss = 0.39626040\n",
      "Iteration 187, loss = 0.39591510\n",
      "Iteration 188, loss = 0.39584586\n",
      "Iteration 189, loss = 0.39569323\n",
      "Iteration 190, loss = 0.39553429\n",
      "Iteration 191, loss = 0.39522100\n",
      "Iteration 192, loss = 0.39529325\n",
      "Iteration 193, loss = 0.39479157\n",
      "Iteration 194, loss = 0.39480780\n",
      "Iteration 195, loss = 0.39478172\n",
      "Iteration 196, loss = 0.39431907\n",
      "Iteration 197, loss = 0.39425127\n",
      "Iteration 198, loss = 0.39410598\n",
      "Iteration 199, loss = 0.39399821\n",
      "Iteration 200, loss = 0.39359271\n",
      "Iteration 1, loss = 0.75442427\n",
      "Iteration 2, loss = 0.70803020\n",
      "Iteration 3, loss = 0.66862049\n",
      "Iteration 4, loss = 0.63582109\n",
      "Iteration 5, loss = 0.60755083\n",
      "Iteration 6, loss = 0.58374915\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "Iteration 7, loss = 0.56431470\n",
      "Iteration 8, loss = 0.54643150\n",
      "Iteration 9, loss = 0.53126811\n",
      "Iteration 10, loss = 0.51786176\n",
      "Iteration 11, loss = 0.50649546\n",
      "Iteration 12, loss = 0.49679102\n",
      "Iteration 13, loss = 0.48823918\n",
      "Iteration 14, loss = 0.48031866\n",
      "Iteration 15, loss = 0.47425185\n",
      "Iteration 16, loss = 0.46874799\n",
      "Iteration 17, loss = 0.46482924\n",
      "Iteration 18, loss = 0.46079837\n",
      "Iteration 19, loss = 0.45728654\n",
      "Iteration 20, loss = 0.45507408\n",
      "Iteration 21, loss = 0.45291126\n",
      "Iteration 22, loss = 0.45088138\n",
      "Iteration 23, loss = 0.44940744\n",
      "Iteration 24, loss = 0.44822869\n",
      "Iteration 25, loss = 0.44722240\n",
      "Iteration 26, loss = 0.44629803\n",
      "Iteration 27, loss = 0.44561259\n",
      "Iteration 28, loss = 0.44518183\n",
      "Iteration 29, loss = 0.44458657\n",
      "Iteration 30, loss = 0.44410195\n",
      "Iteration 31, loss = 0.44380084\n",
      "Iteration 32, loss = 0.44352698\n",
      "Iteration 33, loss = 0.44329762\n",
      "Iteration 34, loss = 0.44295503\n",
      "Iteration 35, loss = 0.44264666\n",
      "Iteration 36, loss = 0.44256458\n",
      "Iteration 37, loss = 0.44233219\n",
      "Iteration 38, loss = 0.44205944\n",
      "Iteration 39, loss = 0.44184466\n",
      "Iteration 40, loss = 0.44179700\n",
      "Iteration 41, loss = 0.44154258\n",
      "Iteration 42, loss = 0.44139890\n",
      "Iteration 43, loss = 0.44118367\n",
      "Iteration 44, loss = 0.44107569\n",
      "Iteration 45, loss = 0.44086260\n",
      "Iteration 46, loss = 0.44071880\n",
      "Iteration 47, loss = 0.44049257\n",
      "Iteration 48, loss = 0.44037084\n",
      "Iteration 49, loss = 0.44025909\n",
      "Iteration 50, loss = 0.44018186\n",
      "Iteration 51, loss = 0.43993274\n",
      "Iteration 52, loss = 0.43980323\n",
      "Iteration 53, loss = 0.43968179\n",
      "Iteration 54, loss = 0.43943121\n",
      "Iteration 55, loss = 0.43932192\n",
      "Iteration 56, loss = 0.43907868\n",
      "Iteration 57, loss = 0.43897596\n",
      "Iteration 58, loss = 0.43913512\n",
      "Iteration 59, loss = 0.43867992\n",
      "Iteration 60, loss = 0.43851774\n",
      "Iteration 61, loss = 0.43841581\n",
      "Iteration 62, loss = 0.43819191\n",
      "Iteration 63, loss = 0.43817790\n",
      "Iteration 64, loss = 0.43803119\n",
      "Iteration 65, loss = 0.43790882\n",
      "Iteration 66, loss = 0.43771400\n",
      "Iteration 67, loss = 0.43758214\n",
      "Iteration 68, loss = 0.43744820\n",
      "Iteration 69, loss = 0.43727883\n",
      "Iteration 70, loss = 0.43725240\n",
      "Iteration 71, loss = 0.43693794\n",
      "Iteration 72, loss = 0.43683248\n",
      "Iteration 73, loss = 0.43660157\n",
      "Iteration 74, loss = 0.43654354\n",
      "Iteration 75, loss = 0.43627440\n",
      "Iteration 76, loss = 0.43621073\n",
      "Iteration 77, loss = 0.43612404\n",
      "Iteration 78, loss = 0.43602670\n",
      "Iteration 79, loss = 0.43570727\n",
      "Iteration 80, loss = 0.43560422\n",
      "Iteration 81, loss = 0.43545866\n",
      "Iteration 82, loss = 0.43526386\n",
      "Iteration 83, loss = 0.43515149\n",
      "Iteration 84, loss = 0.43505209\n",
      "Iteration 85, loss = 0.43490346\n",
      "Iteration 86, loss = 0.43467696\n",
      "Iteration 87, loss = 0.43501318\n",
      "Iteration 88, loss = 0.43455529\n",
      "Iteration 89, loss = 0.43429149\n",
      "Iteration 90, loss = 0.43409804\n",
      "Iteration 91, loss = 0.43394665\n",
      "Iteration 92, loss = 0.43396080\n",
      "Iteration 93, loss = 0.43363639\n",
      "Iteration 94, loss = 0.43354060\n",
      "Iteration 95, loss = 0.43333802\n",
      "Iteration 96, loss = 0.43323735\n",
      "Iteration 97, loss = 0.43313029\n",
      "Iteration 98, loss = 0.43285165\n",
      "Iteration 99, loss = 0.43273329\n",
      "Iteration 100, loss = 0.43246640\n",
      "Iteration 101, loss = 0.43277102\n",
      "Iteration 102, loss = 0.43233421\n",
      "Iteration 103, loss = 0.43224102\n",
      "Iteration 104, loss = 0.43201897\n",
      "Iteration 105, loss = 0.43184732\n",
      "Iteration 106, loss = 0.43159943\n",
      "Iteration 107, loss = 0.43156382\n",
      "Iteration 108, loss = 0.43146918\n",
      "Iteration 109, loss = 0.43135155\n",
      "Iteration 110, loss = 0.43116562\n",
      "Iteration 111, loss = 0.43078771\n",
      "Iteration 112, loss = 0.43077023\n",
      "Iteration 113, loss = 0.43046701\n",
      "Iteration 114, loss = 0.43032309\n",
      "Iteration 115, loss = 0.43028046\n",
      "Iteration 116, loss = 0.43008150\n",
      "Iteration 117, loss = 0.42988055\n",
      "Iteration 118, loss = 0.42975883\n",
      "Iteration 119, loss = 0.42972280\n",
      "Iteration 120, loss = 0.42962508\n",
      "Iteration 121, loss = 0.42923943\n",
      "Iteration 122, loss = 0.42912292\n",
      "Iteration 123, loss = 0.42894796\n",
      "Iteration 124, loss = 0.42887856\n",
      "Iteration 125, loss = 0.42861032\n",
      "Iteration 126, loss = 0.42868583\n",
      "Iteration 127, loss = 0.42821252\n",
      "Iteration 128, loss = 0.42811275\n",
      "Iteration 129, loss = 0.42786016\n",
      "Iteration 130, loss = 0.42775674\n",
      "Iteration 131, loss = 0.42757188\n",
      "Iteration 132, loss = 0.42740187\n",
      "Iteration 133, loss = 0.42737500\n",
      "Iteration 134, loss = 0.42705772\n",
      "Iteration 135, loss = 0.42696462\n",
      "Iteration 136, loss = 0.42678116\n",
      "Iteration 137, loss = 0.42666018\n",
      "Iteration 138, loss = 0.42623433\n",
      "Iteration 139, loss = 0.42634011\n",
      "Iteration 140, loss = 0.42609205\n",
      "Iteration 141, loss = 0.42592171\n",
      "Iteration 142, loss = 0.42567153\n",
      "Iteration 143, loss = 0.42558842\n",
      "Iteration 144, loss = 0.42542322\n",
      "Iteration 145, loss = 0.42520055\n",
      "Iteration 146, loss = 0.42493076\n",
      "Iteration 147, loss = 0.42487340\n",
      "Iteration 148, loss = 0.42461854\n",
      "Iteration 149, loss = 0.42438149\n",
      "Iteration 150, loss = 0.42428471\n",
      "Iteration 151, loss = 0.42407388\n",
      "Iteration 152, loss = 0.42401548\n",
      "Iteration 153, loss = 0.42407066\n",
      "Iteration 154, loss = 0.42350426\n",
      "Iteration 155, loss = 0.42353166\n",
      "Iteration 156, loss = 0.42312833\n",
      "Iteration 157, loss = 0.42300443\n",
      "Iteration 158, loss = 0.42288069\n",
      "Iteration 159, loss = 0.42261914\n",
      "Iteration 160, loss = 0.42242586\n",
      "Iteration 161, loss = 0.42218757\n",
      "Iteration 162, loss = 0.42198335\n",
      "Iteration 163, loss = 0.42187465\n",
      "Iteration 164, loss = 0.42170568\n",
      "Iteration 165, loss = 0.42144714\n",
      "Iteration 166, loss = 0.42137737\n",
      "Iteration 167, loss = 0.42113434\n",
      "Iteration 168, loss = 0.42095290\n",
      "Iteration 169, loss = 0.42080987\n",
      "Iteration 170, loss = 0.42063489\n",
      "Iteration 171, loss = 0.42025767\n",
      "Iteration 172, loss = 0.42010644\n",
      "Iteration 173, loss = 0.41997494\n",
      "Iteration 174, loss = 0.41985390\n",
      "Iteration 175, loss = 0.41971105\n",
      "Iteration 176, loss = 0.41946506\n",
      "Iteration 177, loss = 0.41917772\n",
      "Iteration 178, loss = 0.41894615\n",
      "Iteration 179, loss = 0.41884738\n",
      "Iteration 180, loss = 0.41860682\n",
      "Iteration 181, loss = 0.41834385\n",
      "Iteration 182, loss = 0.41820518\n",
      "Iteration 183, loss = 0.41806751\n",
      "Iteration 184, loss = 0.41796441\n",
      "Iteration 185, loss = 0.41782257\n",
      "Iteration 186, loss = 0.41752844\n",
      "Iteration 187, loss = 0.41723619\n",
      "Iteration 188, loss = 0.41700611\n",
      "Iteration 189, loss = 0.41682847\n",
      "Iteration 190, loss = 0.41657302\n",
      "Iteration 191, loss = 0.41642783\n",
      "Iteration 192, loss = 0.41638565\n",
      "Iteration 193, loss = 0.41593795\n",
      "Iteration 194, loss = 0.41588253\n",
      "Iteration 195, loss = 0.41582744\n",
      "Iteration 196, loss = 0.41537603\n",
      "Iteration 197, loss = 0.41547250\n",
      "Iteration 198, loss = 0.41518620\n",
      "Iteration 199, loss = 0.41506482\n",
      "Iteration 200, loss = 0.41488463\n",
      "Iteration 1, loss = 0.75065251\n",
      "Iteration 2, loss = 0.70190708\n",
      "Iteration 3, loss = 0.65722314\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "Iteration 4, loss = 0.62139734\n",
      "Iteration 5, loss = 0.59159805\n",
      "Iteration 6, loss = 0.56586290\n",
      "Iteration 7, loss = 0.54358053\n",
      "Iteration 8, loss = 0.52579304\n",
      "Iteration 9, loss = 0.50911544\n",
      "Iteration 10, loss = 0.49552867\n",
      "Iteration 11, loss = 0.48340195\n",
      "Iteration 12, loss = 0.47317948\n",
      "Iteration 13, loss = 0.46307054\n",
      "Iteration 14, loss = 0.45520104\n",
      "Iteration 15, loss = 0.44811142\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'alpha': list(10.0 ** -np.arange(1, 7)), 'activation': ('identity', 'logistic', 'tanh', 'relu'),\n",
    "                     'random_state': [0], 'verbose' : [3]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        MLPClassifier(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train_norm, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_norm)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-30T11:27:31.314Z"
    },
    "cell_id": "00013-ce689dd9-bd75-4ca8-b58c-d8c954b41a10",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 33975,
    "execution_start": 1612007312153,
    "source_hash": "78e92364"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-458ad9794a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \"\"\"\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[0;32m--> 405\u001b[0;31m                             intercept_grads, layer_units)\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[1;32m    497\u001b[0m                     \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 },\n\u001b[0;32m--> 499\u001b[0;31m                 args=(X, y, activations, deltas, coef_grads, intercept_grads))\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_optimize_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 620\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    621\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[0;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0;32m--> 209\u001b[0;31m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    286\u001b[0m             self._compute_loss_grad(\n\u001b[1;32m    287\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 intercept_grads)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_compute_loss_grad\u001b[0;34m(self, layer, n_samples, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \"\"\"\n\u001b[1;32m    158\u001b[0m         coef_grads[layer] = safe_sparse_dot(activations[layer].T,\n\u001b[0;32m--> 159\u001b[0;31m                                             deltas[layer])\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mcoef_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mcoef_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'solver': ['lbfgs'], 'alpha': list(10.0 ** -np.arange(1, 7)), 'activation': ['tanh'],\n",
    "                     'random_state': [0]}]\n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(), tuned_parameters)\n",
    "clf.fit(X_train_norm, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test_norm)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6ed92db1-0446-4d66-be0b-3e2d2680e1f7",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
